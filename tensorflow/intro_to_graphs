{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "headers"
   },
   "source": [
    "Project: /overview/_project.yaml\n",
    "Book: /overview/_book.yaml\n",
    "\n",
    "<link rel=\"stylesheet\" href=\"/site-assets/css/style.css\">\n",
    "\n",
    "<!-- DO NOT EDIT! Automatically generated file. -->\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6xgB0Oz5eGSQ"
   },
   "source": [
    "# 그래프 및 tf.function 소개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w4zzZVZtQb1w"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/guide/intro_to_graphs\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">TensorFlow.org에서 보기</a></td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/ko/guide/intro_to_graphs.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/ko/guide/intro_to_graphs.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/ko/guide/intro_to_graphs.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RBKqnXI9GOax"
   },
   "source": [
    "## 개요\n",
    "\n",
    "This guide goes beneath the surface of TensorFlow and Keras to demonstrate how TensorFlow works. If you instead want to immediately get started with Keras, check out the [collection of Keras guides](keras/).\n",
    "\n",
    "In this guide, you'll learn how TensorFlow allows you to make simple changes to your code to get graphs, how graphs are stored and represented, and how you can use them to accelerate your models.\n",
    "\n",
    "참고: TensorFlow 1.x에만 익숙한 사용자를 위해 이 가이드는 매우 다른 그래프 뷰를 보여줍니다.\n",
    "\n",
    "**This is a big-picture overview that covers how `tf.function` allows you to switch from eager execution to graph execution.** For a more complete specification of `tf.function`, go to the <a href=\"function\" data-md-type=\"link\">`tf.function` guide</a>.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v0DdlfacAdTZ"
   },
   "source": [
    "### 그래프란 무엇인가요?\n",
    "\n",
    "In the previous three guides, you ran TensorFlow **eagerly**. This means TensorFlow operations are executed by Python, operation by operation, and returning results back to Python.\n",
    "\n",
    "즉시 실행에는 몇 가지 고유한 장점이 있지만 그래프 실행은 Python 외부에서 이식성을 가능하게 하며 성능이 더 우수한 경향이 있습니다. **그래프 실행**은 텐서 계산이 `tf.Graph` 또는 간단히 \"그래프\"라고도 하는 *TensorFlow 그래프*로 실행됨을 의미합니다.\n",
    "\n",
    "**그래프는 계산의 단위를 나타내는 `tf.Operation` 객체와 연산 간에 흐르는 데이터의 단위를 나타내는 `tf.Tensor` 객체의 세트를 포함합니다.** 데이터 구조는 `tf.Graph` 컨텍스트에서 정의됩니다. 그래프는 데이터 구조이므로 원래 Python 코드 없이 모두 저장, 실행 및 복원할 수 있습니다.\n",
    "\n",
    "**그래프는 계산의 단위를 나타내는 `tf.Operation` 객체와 연산 간에 흐르는 데이터의 단위를 나타내는 `tf.Tensor` 객체의 세트를 포함합니다.** 데이터 구조는 `tf.Graph` 컨텍스트에서 정의됩니다. 그래프는 데이터 구조이므로 원래 Python 코드 없이 모두 저장, 실행 및 복원할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FvQ5aBuRGT1o"
   },
   "source": [
    "<img alt=\"A simple TensorFlow graph\" src=\"./images/intro_to_graphs/two-layer-network.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DHpY3avXGITP"
   },
   "source": [
    "### 그래프의 이점\n",
    "\n",
    "그래프를 사용하면 유연성이 크게 향상됩니다. 모바일 애플리케이션, 임베디드 기기 및 백엔드 서버와 같은 Python 인터프리터가 없는 환경에서 TensorFlow 그래프를 사용할 수 있습니다. TensorFlow는 그래프를 Python에서 내보낼 때 저장된 모델의 형식으로 그래프를 사용합니다.\n",
    "\n",
    "그래프는 쉽게 최적화되어 컴파일러가 다음과 같은 변환을 수행할 수 있습니다.\n",
    "\n",
    "- 계산에서 상수 노드를 접어 텐서의 값을 정적으로 추론합니다*(\"일정한 접기\")*.\n",
    "- 독립적인 계산의 하위 부분을 분리하여 스레드 또는 기기 간에 분할합니다.\n",
    "- 공통 하위 표현식을 제거하여 산술 연산을 단순화합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o1x1EOD9GjnB"
   },
   "source": [
    "위와 같은 변환 및 기타 속도 향상을 수행하기 위한 전체 최적화 시스템으로 [Grappler](./graph_optimization.ipynb)가 있습니다.\n",
    "\n",
    "요약하면, 그래프는 TensorFlow가 **빠르게**, **병렬로**, 그리고 효율적으로 **여러 기기에서** 실행할 때 아주 유용합니다.\n",
    "\n",
    "However, you still want to define your machine learning models (or other computations) in Python for convenience, and then automatically construct graphs when you need them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pSZebVuWxDXu"
   },
   "source": [
    "## 그래프 이용하기\n",
    "\n",
    "`tf.function`을 직접 호출 또는 데코레이터로 사용하여 TensorFlow에서 그래프를 만들고 실행합니다. `tf.function`은 일반 함수를 입력으로 받아 `Function`을 반환합니다. <strong data-md-type=\"double_emphasis\">`Function`은 Python 함수로부터 TensorFlow 그래프를 빌드하는 Python callable입니다. Python의 경우와 동일한 방식으로 `Function`를 사용합니다.</strong>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-14T00:38:11.319262Z",
     "iopub.status.busy": "2021-08-14T00:38:11.318662Z",
     "iopub.status.idle": "2021-08-14T00:38:12.703659Z",
     "shell.execute_reply": "2021-08-14T00:38:12.704016Z"
    },
    "id": "goZwOXp_xyQj"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import timeit\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-14T00:38:14.249298Z",
     "iopub.status.busy": "2021-08-14T00:38:13.365172Z",
     "iopub.status.idle": "2021-08-14T00:38:14.700276Z",
     "shell.execute_reply": "2021-08-14T00:38:14.699780Z"
    },
    "id": "HKbLeJ1y0Umi"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-14 00:38:13.353844: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-14 00:38:13.361949: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-14 00:38:13.362842: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-14 00:38:13.364550: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-08-14 00:38:13.365128: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-14 00:38:13.366098: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-14 00:38:13.367022: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-14 00:38:13.955497: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-14 00:38:13.956396: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-14 00:38:13.957224: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-14 00:38:13.958040: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14648 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:05.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-14 00:38:14.688889: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    }
   ],
   "source": [
    "# Define a Python function.\n",
    "def a_regular_function(x, y, b):\n",
    "  x = tf.matmul(x, y)\n",
    "  x = x + b\n",
    "  return x\n",
    "\n",
    "# `a_function_that_uses_a_graph` is a TensorFlow `Function`.\n",
    "a_function_that_uses_a_graph = tf.function(a_regular_function)\n",
    "\n",
    "# Make some tensors.\n",
    "x1 = tf.constant([[1.0, 2.0]])\n",
    "y1 = tf.constant([[2.0], [3.0]])\n",
    "b1 = tf.constant(4.0)\n",
    "\n",
    "orig_value = a_regular_function(x1, y1, b1).numpy()\n",
    "# Call a `Function` like a Python function.\n",
    "tf_function_value = a_function_that_uses_a_graph(x1, y1, b1).numpy()\n",
    "assert(orig_value == tf_function_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PNvuAYpdrTOf"
   },
   "source": [
    "겉보기에 `Function`은 TensorFlow 연산을 사용하여 작성하는 일반 함수처럼 보입니다. 그러나 [그 안을 들여다 보면](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/eager/def_function.py) *매우 다릅니다*. `Function`**는 [하나의 API 뒤에서 여러 `tf.Graph`](#polymorphism_one_function_many_graphs)를 캡슐화합니다.** 바로 이런 이유로 `Function`이 속도 및 배포 가능성과 같은 [그래프 실행의 이점](#the_benefits_of_graphs)을 제공하는 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MT7U8ozok0gV"
   },
   "source": [
    "`tf.function`은 함수 및 *이 함수가 호출하는 다른 모든 함수*에 적용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-14T00:38:14.725611Z",
     "iopub.status.busy": "2021-08-14T00:38:14.705800Z",
     "iopub.status.idle": "2021-08-14T00:38:14.771765Z",
     "shell.execute_reply": "2021-08-14T00:38:14.772130Z"
    },
    "id": "rpz08iLplm9F"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12.]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def inner_function(x, y, b):\n",
    "  x = tf.matmul(x, y)\n",
    "  x = x + b\n",
    "  return x\n",
    "\n",
    "# Use the decorator to make `outer_function` a `Function`.\n",
    "@tf.function\n",
    "def outer_function(x):\n",
    "  y = tf.constant([[2.0], [3.0]])\n",
    "  b = tf.constant(4.0)\n",
    "\n",
    "  return inner_function(x, y, b)\n",
    "\n",
    "# Note that the callable will create a graph that\n",
    "# includes `inner_function` as well as `outer_function`.\n",
    "outer_function(tf.constant([[1.0, 2.0]])).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P88fOr88qgCj"
   },
   "source": [
    "TensorFlow 1.x를 사용한 경우 `Placeholder` 또는 `tf.Sesssion`을 정의할 필요가 없었음을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wfeKf0Nr1OEK"
   },
   "source": [
    "### Python 함수를 그래프로 변환하기\n",
    "\n",
    "TensorFlow를 사용하여 작성하는 모든 함수에는 `if-then` 절, 루프, `break`, `return`, `continue` 등과 같은 내장된 TF 연산과 Python 논리가 혼합되어 있습니다. TensorFlow 연산은 `tf.Graph`에 의해 쉽게 캡처되지만 Python 관련 논리는 그래프의 일부가 되기 위해 추가 단계를 거쳐야 합니다. `tf.function`은 AutoGraph(`tf.autograph`)라는 라이브러리를 사용하여 Python 코드를 그래프 생성 코드로 변환합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-14T00:38:14.801642Z",
     "iopub.status.busy": "2021-08-14T00:38:14.777337Z",
     "iopub.status.idle": "2021-08-14T00:38:14.827640Z",
     "shell.execute_reply": "2021-08-14T00:38:14.827988Z"
    },
    "id": "PFObpff1BMEb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First branch, with graph: 1\n",
      "Second branch, with graph: 0\n"
     ]
    }
   ],
   "source": [
    "def simple_relu(x):\n",
    "  if tf.greater(x, 0):\n",
    "    return x\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "# `tf_simple_relu` is a TensorFlow `Function` that wraps `simple_relu`.\n",
    "tf_simple_relu = tf.function(simple_relu)\n",
    "\n",
    "print(\"First branch, with graph:\", tf_simple_relu(tf.constant(1)).numpy())\n",
    "print(\"Second branch, with graph:\", tf_simple_relu(tf.constant(-1)).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hO4DBUNZBMwQ"
   },
   "source": [
    "Though it is unlikely that you will need to view graphs directly, you can inspect the outputs to check the exact results. These are not easy to read, so no need to look too carefully!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-14T00:38:14.832083Z",
     "iopub.status.busy": "2021-08-14T00:38:14.831509Z",
     "iopub.status.idle": "2021-08-14T00:38:14.835525Z",
     "shell.execute_reply": "2021-08-14T00:38:14.835068Z"
    },
    "id": "lAKaat3w0gnn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def tf__simple_relu(x):\n",
      "    with ag__.FunctionScope('simple_relu', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
      "        do_return = False\n",
      "        retval_ = ag__.UndefinedReturnValue()\n",
      "\n",
      "        def get_state():\n",
      "            return (do_return, retval_)\n",
      "\n",
      "        def set_state(vars_):\n",
      "            nonlocal retval_, do_return\n",
      "            (do_return, retval_) = vars_\n",
      "\n",
      "        def if_body():\n",
      "            nonlocal retval_, do_return\n",
      "            try:\n",
      "                do_return = True\n",
      "                retval_ = ag__.ld(x)\n",
      "            except:\n",
      "                do_return = False\n",
      "                raise\n",
      "\n",
      "        def else_body():\n",
      "            nonlocal retval_, do_return\n",
      "            try:\n",
      "                do_return = True\n",
      "                retval_ = 0\n",
      "            except:\n",
      "                do_return = False\n",
      "                raise\n",
      "        ag__.if_stmt(ag__.converted_call(ag__.ld(tf).greater, (ag__.ld(x), 0), None, fscope), if_body, else_body, get_state, set_state, ('do_return', 'retval_'), 2)\n",
      "        return fscope.ret(retval_, do_return)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This is the graph-generating output of AutoGraph.\n",
    "print(tf.autograph.to_code(simple_relu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-14T00:38:14.839308Z",
     "iopub.status.busy": "2021-08-14T00:38:14.838599Z",
     "iopub.status.idle": "2021-08-14T00:38:14.841936Z",
     "shell.execute_reply": "2021-08-14T00:38:14.841492Z"
    },
    "id": "8x6RAqza1UWf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node {\n",
      "  name: \"x\"\n",
      "  op: \"Placeholder\"\n",
      "  attr {\n",
      "    key: \"_user_specified_name\"\n",
      "    value {\n",
      "      s: \"x\"\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"shape\"\n",
      "    value {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"Greater/y\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_INT32\n",
      "        tensor_shape {\n",
      "        }\n",
      "        int_val: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"Greater\"\n",
      "  op: \"Greater\"\n",
      "  input: \"x\"\n",
      "  input: \"Greater/y\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"cond\"\n",
      "  op: \"StatelessIf\"\n",
      "  input: \"Greater\"\n",
      "  input: \"x\"\n",
      "  attr {\n",
      "    key: \"Tcond\"\n",
      "    value {\n",
      "      type: DT_BOOL\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"Tin\"\n",
      "    value {\n",
      "      list {\n",
      "        type: DT_INT32\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"Tout\"\n",
      "    value {\n",
      "      list {\n",
      "        type: DT_BOOL\n",
      "        type: DT_INT32\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_lower_using_switch_merge\"\n",
      "    value {\n",
      "      b: true\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_read_only_resource_inputs\"\n",
      "    value {\n",
      "      list {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"else_branch\"\n",
      "    value {\n",
      "      func {\n",
      "        name: \"cond_false_34\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"output_shapes\"\n",
      "    value {\n",
      "      list {\n",
      "        shape {\n",
      "        }\n",
      "        shape {\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"then_branch\"\n",
      "    value {\n",
      "      func {\n",
      "        name: \"cond_true_33\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"cond/Identity\"\n",
      "  op: \"Identity\"\n",
      "  input: \"cond\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_BOOL\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"cond/Identity_1\"\n",
      "  op: \"Identity\"\n",
      "  input: \"cond:1\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"Identity\"\n",
      "  op: \"Identity\"\n",
      "  input: \"cond/Identity_1\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "library {\n",
      "  function {\n",
      "    signature {\n",
      "      name: \"cond_false_34\"\n",
      "      input_arg {\n",
      "        name: \"cond_placeholder\"\n",
      "        type: DT_INT32\n",
      "      }\n",
      "      output_arg {\n",
      "        name: \"cond_identity\"\n",
      "        type: DT_BOOL\n",
      "      }\n",
      "      output_arg {\n",
      "        name: \"cond_identity_1\"\n",
      "        type: DT_INT32\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Const\"\n",
      "      op: \"Const\"\n",
      "      attr {\n",
      "        key: \"dtype\"\n",
      "        value {\n",
      "          type: DT_BOOL\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"value\"\n",
      "        value {\n",
      "          tensor {\n",
      "            dtype: DT_BOOL\n",
      "            tensor_shape {\n",
      "            }\n",
      "            bool_val: true\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      experimental_debug_info {\n",
      "        original_node_names: \"cond/Const\"\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Const_1\"\n",
      "      op: \"Const\"\n",
      "      attr {\n",
      "        key: \"dtype\"\n",
      "        value {\n",
      "          type: DT_BOOL\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"value\"\n",
      "        value {\n",
      "          tensor {\n",
      "            dtype: DT_BOOL\n",
      "            tensor_shape {\n",
      "            }\n",
      "            bool_val: true\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      experimental_debug_info {\n",
      "        original_node_names: \"cond/Const_1\"\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Const_2\"\n",
      "      op: \"Const\"\n",
      "      attr {\n",
      "        key: \"dtype\"\n",
      "        value {\n",
      "          type: DT_INT32\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"value\"\n",
      "        value {\n",
      "          tensor {\n",
      "            dtype: DT_INT32\n",
      "            tensor_shape {\n",
      "            }\n",
      "            int_val: 0\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      experimental_debug_info {\n",
      "        original_node_names: \"cond/Const_2\"\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Const_3\"\n",
      "      op: \"Const\"\n",
      "      attr {\n",
      "        key: \"dtype\"\n",
      "        value {\n",
      "          type: DT_BOOL\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"value\"\n",
      "        value {\n",
      "          tensor {\n",
      "            dtype: DT_BOOL\n",
      "            tensor_shape {\n",
      "            }\n",
      "            bool_val: true\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      experimental_debug_info {\n",
      "        original_node_names: \"cond/Const_3\"\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Identity\"\n",
      "      op: \"Identity\"\n",
      "      input: \"cond/Const_3:output:0\"\n",
      "      attr {\n",
      "        key: \"T\"\n",
      "        value {\n",
      "          type: DT_BOOL\n",
      "        }\n",
      "      }\n",
      "      experimental_debug_info {\n",
      "        original_node_names: \"cond/Identity\"\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Const_4\"\n",
      "      op: \"Const\"\n",
      "      attr {\n",
      "        key: \"dtype\"\n",
      "        value {\n",
      "          type: DT_INT32\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"value\"\n",
      "        value {\n",
      "          tensor {\n",
      "            dtype: DT_INT32\n",
      "            tensor_shape {\n",
      "            }\n",
      "            int_val: 0\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      experimental_debug_info {\n",
      "        original_node_names: \"cond/Const_4\"\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Identity_1\"\n",
      "      op: \"Identity\"\n",
      "      input: \"cond/Const_4:output:0\"\n",
      "      attr {\n",
      "        key: \"T\"\n",
      "        value {\n",
      "          type: DT_INT32\n",
      "        }\n",
      "      }\n",
      "      experimental_debug_info {\n",
      "        original_node_names: \"cond/Identity_1\"\n",
      "      }\n",
      "    }\n",
      "    ret {\n",
      "      key: \"cond_identity\"\n",
      "      value: \"cond/Identity:output:0\"\n",
      "    }\n",
      "    ret {\n",
      "      key: \"cond_identity_1\"\n",
      "      value: \"cond/Identity_1:output:0\"\n",
      "    }\n",
      "    attr {\n",
      "      key: \"_construction_context\"\n",
      "      value {\n",
      "        s: \"kEagerRuntime\"\n",
      "      }\n",
      "    }\n",
      "    arg_attr {\n",
      "      key: 0\n",
      "      value {\n",
      "        attr {\n",
      "          key: \"_output_shapes\"\n",
      "          value {\n",
      "            list {\n",
      "              shape {\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  function {\n",
      "    signature {\n",
      "      name: \"cond_true_33\"\n",
      "      input_arg {\n",
      "        name: \"cond_identity_1_x\"\n",
      "        type: DT_INT32\n",
      "      }\n",
      "      output_arg {\n",
      "        name: \"cond_identity\"\n",
      "        type: DT_BOOL\n",
      "      }\n",
      "      output_arg {\n",
      "        name: \"cond_identity_1\"\n",
      "        type: DT_INT32\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Const\"\n",
      "      op: \"Const\"\n",
      "      attr {\n",
      "        key: \"dtype\"\n",
      "        value {\n",
      "          type: DT_BOOL\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"value\"\n",
      "        value {\n",
      "          tensor {\n",
      "            dtype: DT_BOOL\n",
      "            tensor_shape {\n",
      "            }\n",
      "            bool_val: true\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      experimental_debug_info {\n",
      "        original_node_names: \"cond/Const\"\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Identity\"\n",
      "      op: \"Identity\"\n",
      "      input: \"cond/Const:output:0\"\n",
      "      attr {\n",
      "        key: \"T\"\n",
      "        value {\n",
      "          type: DT_BOOL\n",
      "        }\n",
      "      }\n",
      "      experimental_debug_info {\n",
      "        original_node_names: \"cond/Identity\"\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Identity_1\"\n",
      "      op: \"Identity\"\n",
      "      input: \"cond_identity_1_x\"\n",
      "      attr {\n",
      "        key: \"T\"\n",
      "        value {\n",
      "          type: DT_INT32\n",
      "        }\n",
      "      }\n",
      "      experimental_debug_info {\n",
      "        original_node_names: \"cond/Identity_1\"\n",
      "      }\n",
      "    }\n",
      "    ret {\n",
      "      key: \"cond_identity\"\n",
      "      value: \"cond/Identity:output:0\"\n",
      "    }\n",
      "    ret {\n",
      "      key: \"cond_identity_1\"\n",
      "      value: \"cond/Identity_1:output:0\"\n",
      "    }\n",
      "    attr {\n",
      "      key: \"_construction_context\"\n",
      "      value {\n",
      "        s: \"kEagerRuntime\"\n",
      "      }\n",
      "    }\n",
      "    arg_attr {\n",
      "      key: 0\n",
      "      value {\n",
      "        attr {\n",
      "          key: \"_output_shapes\"\n",
      "          value {\n",
      "            list {\n",
      "              shape {\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "versions {\n",
      "  producer: 808\n",
      "  min_consumer: 12\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This is the graph itself.\n",
    "print(tf_simple_relu.get_concrete_function(tf.constant(1)).graph.as_graph_def())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GZ4Ieg6tBE6l"
   },
   "source": [
    "대부분의 경우, `tf.function`은 특별한 고려없이 작동합니다. 그러나 몇 가지 주의 사항이 있으며 <a>tf.function 안내서</a>와 [전체 AutoGraph 참조서](./function.ipynb)가 도움이 될 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sIpc_jfjEZEg"
   },
   "source": [
    "### 다형성: 하나의 `Function`, 다수의 그래프\n",
    "\n",
    "`tf.Graph`는 특정 유형의 입력에 특화되어 있습니다(예: 특정 [`dtype`](https://www.tensorflow.org/api_docs/python/tf/dtypes/DType)을 가진 텐서 또는 동일한 [`id()`](https://docs.python.org/3/library/functions.html#id%5D)를 가진 객체).\n",
    "\n",
    "새로운 `dtypes` 및 인수의 형상을 사용하여 `Function`을 호출할 때마다 `Function`은 새 인수에 대한 새로운 `tf.Graph`를 생성합니다. `tf.Graph` 입력의 `dtypes`과 형상은 **입력 서명** 또는 간단히 **서명**이라고 합니다.\n",
    "\n",
    "`Function`은 해당 서명에 대응하는 `tf.Graph`를 `ConcreteFunction`에 저장합니다. <strong data-md-type=\"double_emphasis\">`ConcreteFunction`은 `tf.Graph`를 감싸는 래퍼입니다.</strong>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-14T00:38:14.860525Z",
     "iopub.status.busy": "2021-08-14T00:38:14.846972Z",
     "iopub.status.idle": "2021-08-14T00:38:14.887220Z",
     "shell.execute_reply": "2021-08-14T00:38:14.886762Z"
    },
    "id": "LOASwhbvIv_T"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(5.5, shape=(), dtype=float32)\n",
      "tf.Tensor([1. 0.], shape=(2,), dtype=float32)\n",
      "tf.Tensor([3. 0.], shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def my_relu(x):\n",
    "  return tf.maximum(0., x)\n",
    "\n",
    "# `my_relu` creates new graphs as it sees more signatures.\n",
    "print(my_relu(tf.constant(5.5)))\n",
    "print(my_relu([1, -1]))\n",
    "print(my_relu(tf.constant([3., -3.])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1qRtw7R4KL9X"
   },
   "source": [
    "`Function`이 이 서명으로 이미 호출된 경우, `Function`은 새 `tf.Graph`를 생성하지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-14T00:38:14.891563Z",
     "iopub.status.busy": "2021-08-14T00:38:14.890938Z",
     "iopub.status.idle": "2021-08-14T00:38:14.894863Z",
     "shell.execute_reply": "2021-08-14T00:38:14.894432Z"
    },
    "id": "TjjbnL5OKNDP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor([0. 1.], shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# These two calls do *not* create new graphs.\n",
    "print(my_relu(tf.constant(-2.5))) # Signature matches `tf.constant(5.5)`.\n",
    "print(my_relu(tf.constant([-1., 1.]))) # Signature matches `tf.constant([3., -3.])`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UohRmexhIpvQ"
   },
   "source": [
    "여러 그래프로 뒷받침된다는 점에서 `Function`는 **다형성**입니다. 그 결과, 단일 `tf.Graph`로 나타낼 수 있는 것보다 더 많은 입력 유형을 지원할 수 있을뿐만 아니라 `tf.Graph`가 더 우수한 성능을 갖도록 최적화할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-14T00:38:14.898703Z",
     "iopub.status.busy": "2021-08-14T00:38:14.898142Z",
     "iopub.status.idle": "2021-08-14T00:38:14.900375Z",
     "shell.execute_reply": "2021-08-14T00:38:14.900762Z"
    },
    "id": "dxzqebDYFmLy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_relu(x)\n",
      "  Args:\n",
      "    x: float32 Tensor, shape=()\n",
      "  Returns:\n",
      "    float32 Tensor, shape=()\n",
      "\n",
      "my_relu(x=[1, -1])\n",
      "  Returns:\n",
      "    float32 Tensor, shape=(2,)\n",
      "\n",
      "my_relu(x)\n",
      "  Args:\n",
      "    x: float32 Tensor, shape=(2,)\n",
      "  Returns:\n",
      "    float32 Tensor, shape=(2,)\n"
     ]
    }
   ],
   "source": [
    "# There are three `ConcreteFunction`s (one for each graph) in `my_relu`.\n",
    "# The `ConcreteFunction` also knows the return type and shape!\n",
    "print(my_relu.pretty_printed_concrete_signatures())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V11zkxU22XeD"
   },
   "source": [
    "## `tf.function` 사용하기\n",
    "\n",
    "So far, you've learned how to convert a Python function into a graph simply by using `tf.function` as a decorator or wrapper. But in practice, getting `tf.function` to work correctly can be tricky! In the following sections, you'll learn how you can make your code work as expected with `tf.function`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yp_n0B5-P0RU"
   },
   "source": [
    "### 그래프 실행 vs 즉시 실행\n",
    "\n",
    "`Function`의 코드는 즉시 실행 또는 그래프 실행이 가능합니다. 기본적으로 `Function`은 코드를 그래프로 실행합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-14T00:38:14.905374Z",
     "iopub.status.busy": "2021-08-14T00:38:14.904844Z",
     "iopub.status.idle": "2021-08-14T00:38:14.906437Z",
     "shell.execute_reply": "2021-08-14T00:38:14.906762Z"
    },
    "id": "_R0BOvBFxqVZ"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def get_MSE(y_true, y_pred):\n",
    "  sq_diff = tf.pow(y_true - y_pred, 2)\n",
    "  return tf.reduce_mean(sq_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-14T00:38:14.911269Z",
     "iopub.status.busy": "2021-08-14T00:38:14.910656Z",
     "iopub.status.idle": "2021-08-14T00:38:14.914071Z",
     "shell.execute_reply": "2021-08-14T00:38:14.913636Z"
    },
    "id": "zikMVPGhmDET"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([7 5 8 9 5], shape=(5,), dtype=int32)\n",
      "tf.Tensor([9 1 6 0 0], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "y_true = tf.random.uniform([5], maxval=10, dtype=tf.int32)\n",
    "y_pred = tf.random.uniform([5], maxval=10, dtype=tf.int32)\n",
    "print(y_true)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-14T00:38:14.917684Z",
     "iopub.status.busy": "2021-08-14T00:38:14.916931Z",
     "iopub.status.idle": "2021-08-14T00:38:14.952517Z",
     "shell.execute_reply": "2021-08-14T00:38:14.952842Z"
    },
    "id": "07r08Dh158ft"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=26>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_MSE(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cyZNCRcQorGO"
   },
   "source": [
    "`Function`의 그래프가 동등한 Python 함수와 같은 계산을 수행하는지 확인하기 위해 `tf.config.run_functions_eagerly(True)`를 이용해 즉시 실행하도록 할 수 있습니다. <strong data-md-type=\"double_emphasis\">코드를 정상적으로 실행하는 대신 그래프를 생성하고 실행하는 `Function`의 역할을 해제</strong>시킬 때 스위치와 같이 이용되는 코드입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-14T00:38:14.956582Z",
     "iopub.status.busy": "2021-08-14T00:38:14.956059Z",
     "iopub.status.idle": "2021-08-14T00:38:14.957957Z",
     "shell.execute_reply": "2021-08-14T00:38:14.957561Z"
    },
    "id": "lKoF6NjPoI8w"
   },
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-14T00:38:14.961604Z",
     "iopub.status.busy": "2021-08-14T00:38:14.960914Z",
     "iopub.status.idle": "2021-08-14T00:38:14.964499Z",
     "shell.execute_reply": "2021-08-14T00:38:14.964094Z"
    },
    "id": "9ZLqTyn0oKeM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=26>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_MSE(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-14T00:38:14.967797Z",
     "iopub.status.busy": "2021-08-14T00:38:14.967287Z",
     "iopub.status.idle": "2021-08-14T00:38:14.969350Z",
     "shell.execute_reply": "2021-08-14T00:38:14.968888Z"
    },
    "id": "cV7daQW9odn-"
   },
   "outputs": [],
   "source": [
    "# Don't forget to set it back when you are done.\n",
    "tf.config.run_functions_eagerly(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DKT3YBsqy0x4"
   },
   "source": [
    "However, `Function` can behave differently under graph and eager execution. The Python [`print`](https://docs.python.org/3/library/functions.html#print) function is one example of how these two modes differ. Let's check out what happens when you insert a `print` statement to your function and call it repeatedly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-14T00:38:14.973548Z",
     "iopub.status.busy": "2021-08-14T00:38:14.973011Z",
     "iopub.status.idle": "2021-08-14T00:38:14.975477Z",
     "shell.execute_reply": "2021-08-14T00:38:14.974927Z"
    },
    "id": "BEJeVeBEoGjV"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def get_MSE(y_true, y_pred):\n",
    "  print(\"Calculating MSE!\")\n",
    "  sq_diff = tf.pow(y_true - y_pred, 2)\n",
    "  return tf.reduce_mean(sq_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3sWTGwX3BzP1"
   },
   "source": [
    "인쇄된 내용을 잘 살펴봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-14T00:38:14.979172Z",
     "iopub.status.busy": "2021-08-14T00:38:14.978320Z",
     "iopub.status.idle": "2021-08-14T00:38:15.015930Z",
     "shell.execute_reply": "2021-08-14T00:38:15.016288Z"
    },
    "id": "3rJIeBg72T9n"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating MSE!\n"
     ]
    }
   ],
   "source": [
    "error = get_MSE(y_true, y_pred)\n",
    "error = get_MSE(y_true, y_pred)\n",
    "error = get_MSE(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WLMXk1uxKQ44"
   },
   "source": [
    "출력 결과가 놀랍지 않나요? **`get_MSE`는 *세 번* 호출되었지만 한 번만 인쇄되었습니다.**\n",
    "\n",
    "설명하자면, `print` 문은 `Function`이 원래 코드를 실행할 때 실행되며 이 때 [\"트레이싱\"](function.ipynb#tracing)이라는 프로세스를 통해 그래프가 생성됩니다. <strong data-md-type=\"double_emphasis\">트레이싱은 TensorFlow 연산을 그래프로 캡처하고 `print`는 그래프에서 캡처되지 않습니다.</strong> 이 그래프는 세 번의 모든 호출시 실행되지만 **Python 코드를 다시 실행하지는 않습니다.**\n",
    "\n",
    "실제로 그런지 검사하기 위해 그래프 실행을 해제하고 비교해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-14T00:38:15.019471Z",
     "iopub.status.busy": "2021-08-14T00:38:15.018440Z",
     "iopub.status.idle": "2021-08-14T00:38:15.021639Z",
     "shell.execute_reply": "2021-08-14T00:38:15.021188Z"
    },
    "id": "oFSxRtcptYpe"
   },
   "outputs": [],
   "source": [
    "# Now, globally set everything to run eagerly to force eager execution.\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-14T00:38:15.026251Z",
     "iopub.status.busy": "2021-08-14T00:38:15.025385Z",
     "iopub.status.idle": "2021-08-14T00:38:15.029365Z",
     "shell.execute_reply": "2021-08-14T00:38:15.028930Z"
    },
    "id": "qYxrAtvzNgHR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating MSE!\n",
      "Calculating MSE!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating MSE!\n"
     ]
    }
   ],
   "source": [
    "# Observe what is printed below.\n",
    "error = get_MSE(y_true, y_pred)\n",
    "error = get_MSE(y_true, y_pred)\n",
    "error = get_MSE(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-14T00:38:15.033079Z",
     "iopub.status.busy": "2021-08-14T00:38:15.032440Z",
     "iopub.status.idle": "2021-08-14T00:38:15.034417Z",
     "shell.execute_reply": "2021-08-14T00:38:15.034766Z"
    },
    "id": "_Df6ynXcAaup"
   },
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PUR7qC_bquCn"
   },
   "source": [
    "`print`는 *Python의 부작용*이며 함수를 `Function`으로 변환할 때 알고 있어야 하는 [다른 차이점들](function#limitations)이 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oTZJfV_tccVp"
   },
   "source": [
    "참고: 즉시 및 그래프 실행 모두에서 값을 인쇄하려면 `tf.print`를 대신 사용하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "def6MupG9R0O"
   },
   "source": [
    "###`tf.function` 모범 사례\n",
    "\n",
    "`Function`의 동작에 익숙해지려면 시간이 걸릴 수 있습니다. 빠르게 시작하려는 처음 사용자는 `@tf.function`으로 시험용 함수를 사용해 보면서 즉시 실행에서 그래프 실행으로 이동하는 과정을 체험할 수 있습니다.\n",
    "\n",
    "*`tf.function`을 위한 디자인*은 그래프 호환 TensorFlow 프로그램을 작성하는 가장 좋은 방법일 수 있습니다. 다음은 몇 가지 팁입니다.\n",
    "\n",
    "- `tf.config.run_functions_eagerly`로 즉시 실행과 그래프 실행 사이를 조기에 자주 전환하여 두 모드가 서로 달라지는지, 언제 달라지는지 정확하게 파악합니다.\n",
    "- Python 함수 외부에서 `tf.Variable`을 실행하고 내부에서 수정합니다. `keras.layers`, `keras.Model` 및 `tf.optimizers`와 같이 `tf.Variable`을 사용하는 객체의 경우도 마찬가지입니다.\n",
    "- `tf.Variables` 및 Keras 객체를 제외하고 [외부 Python 변수에 종속되는](function#depending_on_python_global_and_free_variables) 함수 작성을 피합니다.\n",
    "- 텐서 및 기타 TensorFlow 유형을 입력으로 사용하는 함수를 작성하는 것이 좋습니다. 다른 객체 유형을 전달할 수 있지만 [주의해야 합니다](function#depending_on_python_objects)!\n",
    "- 성능 이점을 극대화하기 위해 `tf.function` 하에서 계산이 가능한 한 많이 포함되도록 합니다. 예를 들어 전체 훈룬 스텝 또는 전체 훈룬 루프를 데코레이션합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ViM3oBJVJrDx"
   },
   "source": [
    "## 속도 향상 확인하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A6NHDp7vAKcJ"
   },
   "source": [
    "`tf.function`은 일반적으로 코드의 성능을 향상시키지만 속도 향상의 정도는 실행하는 계산의 종류에 따라 다릅니다. 작은 계산의 경우 그래프를 호출하는 오버헤드에 의해 지배될 수 있습니다. 다음과 같이 성능 차이를 측정할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-14T00:38:15.040098Z",
     "iopub.status.busy": "2021-08-14T00:38:15.039410Z",
     "iopub.status.idle": "2021-08-14T00:38:15.041736Z",
     "shell.execute_reply": "2021-08-14T00:38:15.041289Z"
    },
    "id": "jr7p1BBjauPK"
   },
   "outputs": [],
   "source": [
    "x = tf.random.uniform(shape=[10, 10], minval=-1, maxval=2, dtype=tf.dtypes.int32)\n",
    "\n",
    "def power(x, y):\n",
    "  result = tf.eye(10, dtype=tf.dtypes.int32)\n",
    "  for _ in range(y):\n",
    "    result = tf.matmul(x, result)\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-14T00:38:15.045706Z",
     "iopub.status.busy": "2021-08-14T00:38:15.045136Z",
     "iopub.status.idle": "2021-08-14T00:38:17.042731Z",
     "shell.execute_reply": "2021-08-14T00:38:17.043089Z"
    },
    "id": "ms2yJyAnUYxK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eager execution: 1.9946797530001277\n"
     ]
    }
   ],
   "source": [
    "print(\"Eager execution:\", timeit.timeit(lambda: power(x, 100), number=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-14T00:38:17.048317Z",
     "iopub.status.busy": "2021-08-14T00:38:17.047375Z",
     "iopub.status.idle": "2021-08-14T00:38:17.639028Z",
     "shell.execute_reply": "2021-08-14T00:38:17.639410Z"
    },
    "id": "gUB2mTyRYRAe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph execution: 0.5878890819994922\n"
     ]
    }
   ],
   "source": [
    "power_as_graph = tf.function(power)\n",
    "print(\"Graph execution:\", timeit.timeit(lambda: power_as_graph(x, 100), number=1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q1Pfo5YwwILi"
   },
   "source": [
    "`tf.function` is commonly used to speed up training loops, and you can learn more about it in [Writing a training loop from scratch](keras/writing_a_training_loop_from_scratch#speeding-up_your_training_step_with_tffunction) with Keras.\n",
    "\n",
    "참고: 특히 코드가 TF 제어 흐름에서 과중하고 작은 텐서를 많이 사용하는 경우, 성능 개선의 효과를 높이기 위해 [`tf.function(jit_compile=True)`](https://www.tensorflow.org/xla#explicit_compilation_with_tffunctionjit_compiletrue)를 시도해볼 수도 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sm0bNFp8PX53"
   },
   "source": [
    "### 성능과 상충 관계\n",
    "\n",
    "Graphs can speed up your code, but the process of creating them has some overhead. For some functions, the creation of the graph takes more time than the execution of the graph. **This investment is usually quickly paid back with the performance boost of subsequent executions, but it's important to be aware that the first few  steps of any large model training can be slower due to tracing.**\n",
    "\n",
    "모델 크기에 관계없이, 빈번한 트레이싱은 피해야 합니다. `tf.function` 가이드에 [리트레이싱을 피하기 위해 입력 사양을 설정하고 텐서 인수를 사용하는 방법](function#controlling_retracing)에 관한 설명이 나와 있습니다. 비정상적으로 성능이 저하되는 것으로 판단되면 실수로 리트레이싱하고 있지 않은지 확인하는 것이 좋습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F4InDaTjwmBA"
   },
   "source": [
    "## `Function`은 언제 트레이싱합니까?\n",
    "\n",
    "`Function`이 트레이싱을 수행하는 경우를 알아보려면 코드에 `print` 문을 추가합니다. 대략적인 규칙으로, `Function`은 트레이싱할 때마다 `print` 문을 실행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-14T00:38:17.665945Z",
     "iopub.status.busy": "2021-08-14T00:38:17.645060Z",
     "iopub.status.idle": "2021-08-14T00:38:17.680073Z",
     "shell.execute_reply": "2021-08-14T00:38:17.679579Z"
    },
    "id": "hXtwlbpofLgW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing!\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(11, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def a_function_with_python_side_effect(x):\n",
    "  print(\"Tracing!\") # An eager-only side effect.\n",
    "  return x * x + tf.constant(2)\n",
    "\n",
    "# This is traced the first time.\n",
    "print(a_function_with_python_side_effect(tf.constant(2)))\n",
    "# The second time through, you won't see the side effect.\n",
    "print(a_function_with_python_side_effect(tf.constant(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-14T00:38:17.686757Z",
     "iopub.status.busy": "2021-08-14T00:38:17.685099Z",
     "iopub.status.idle": "2021-08-14T00:38:17.697206Z",
     "shell.execute_reply": "2021-08-14T00:38:17.697558Z"
    },
    "id": "inzSg8yzfNjl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing!\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "Tracing!\n",
      "tf.Tensor(11, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# This retraces each time the Python argument changes,\n",
    "# as a Python argument could be an epoch count or other\n",
    "# hyperparameter.\n",
    "print(a_function_with_python_side_effect(2))\n",
    "print(a_function_with_python_side_effect(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rtN8NW6AfKye"
   },
   "source": [
    "New Python arguments always trigger the creation of a new graph, hence the extra tracing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D1kbr5ocpS6R"
   },
   "source": [
    "## 다음 단계\n",
    "\n",
    "You can learn more about `tf.function` on the API reference page and by following the <a href=\"function\" data-md-type=\"link\">Better performance with `tf.function`</a> guide."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "intro_to_graphs.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}