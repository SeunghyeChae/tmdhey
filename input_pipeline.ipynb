{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "input_pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1K-1_N8ZUzoKVWC-9r-cCUAxX2EO3XTWg",
      "authorship_tag": "ABX9TyNVm7BM5bvHrAZx4v0ztpZA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SeunghyeChae/tmdhey/blob/main/input_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install tensorflow_io"
      ],
      "metadata": {
        "id": "1RMtX_oxbenD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydicom"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYRPr7RFlgmV",
        "outputId": "62608f6d-92a6-467d-9ada-d4ec6fb82a21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydicom\n",
            "  Downloading pydicom-2.2.2-py3-none-any.whl (2.0 MB)\n",
            "\u001b[?25l\r\u001b[K     |▏                               | 10 kB 18.5 MB/s eta 0:00:01\r\u001b[K     |▍                               | 20 kB 26.0 MB/s eta 0:00:01\r\u001b[K     |▌                               | 30 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |▊                               | 40 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |▉                               | 51 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█                               | 61 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 81 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 92 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 102 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 112 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██                              | 122 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 133 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 143 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 153 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 163 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 174 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███                             | 184 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 194 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 204 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 215 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 225 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 235 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████                            | 245 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 256 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 266 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 276 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 286 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 296 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████                           | 307 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 317 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 327 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 337 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 348 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 358 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████                          | 368 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 378 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 389 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 399 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 409 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 419 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████                         | 430 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 440 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 450 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 460 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 471 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████                        | 481 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████                        | 491 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 501 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 512 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 522 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 532 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 542 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 552 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 563 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 573 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 583 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 593 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 604 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 614 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 624 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 634 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 645 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 655 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 665 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 675 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 686 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 696 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 706 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 716 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 727 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 737 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 747 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 757 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 768 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 778 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 788 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 798 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 808 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 819 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 829 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 839 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 849 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 860 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 870 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 880 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 890 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 901 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 911 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 921 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 931 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 942 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 952 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 962 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 972 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 983 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 993 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 1.0 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 1.0 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 1.0 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.0 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 1.0 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 1.1 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 1.1 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 1.1 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 1.1 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.1 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 1.1 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 1.1 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 1.1 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 1.1 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 1.1 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.2 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 1.2 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 1.2 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 1.2 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 1.2 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 1.2 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.2 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 1.2 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 1.2 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.2 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 1.3 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 1.3 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.3 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 1.3 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.3 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 1.3 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.3 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.3 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.3 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 1.4 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.4 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.4 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.4 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.4 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.4 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.4 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.4 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.4 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.4 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.5 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.5 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.5 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.5 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.5 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.5 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.5 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.5 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.5 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.5 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.6 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.6 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.6 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.6 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.6 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.6 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.6 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.6 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.6 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.6 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.7 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.7 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.7 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.7 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.7 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.7 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.7 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.7 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.7 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.8 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.8 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.8 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.8 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.8 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.8 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.8 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.8 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.8 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.8 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.9 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.9 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.9 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.9 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.9 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.9 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.9 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.9 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.9 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.9 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.0 MB 5.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: pydicom\n",
            "Successfully installed pydicom-2.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pydicom as dcm\n",
        "import pathlib\n",
        "import os\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "9atv7m3c3xYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tqdm import tqdm\n",
        "from glob import glob\n",
        "import random\n",
        "import tensorflow as tf\n",
        "\n",
        "dataset_path= '/content/drive/MyDrive/cakd_colab/python_practice/smc/1.3.6.1.4.1.14519.5.2.1.6279.6001.105756658031515062000744821260'\n",
        "\n",
        "def _bytes_feature(value):\n",
        "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
        "    if isinstance(value, type(tf.constant(0))):\n",
        "        value = value.numpy()\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "\n",
        "def _float_feature(value):\n",
        "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
        "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
        "\n",
        "\n",
        "def _int64_feature(value):\n",
        "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
        "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "\n",
        "def make_example(img_str, source_id, filename):\n",
        "    # Create a dictionary with features that may be relevant.\n",
        "    feature = {'image/source_id': _int64_feature(source_id),\n",
        "               'image/filename': _bytes_feature(filename),\n",
        "               'image/encoded': _bytes_feature(img_str),\n",
        "               # -----------------------------------------\n",
        "               'image/height': _int64_feature(shape[0]),\n",
        "               'image/width': _int64_feature(shape[1]),\n",
        "               'image/channels': _int64_feature(shape[2]),\n",
        "               'image/shape': _int64_feature(shape),\n",
        "               'image/image_data':_bytes_feature(image_data.tostring()),\n",
        "               'image/superpixels':_bytes_feature(superpixels.tostring()),\n",
        "               'image/mask_instance':_bytes_feature(mask_instance.tostring()),\n",
        "               'image/mask_class':_bytes_feature(mask_class.tostring()),\n",
        "               'image/class_labels':_int64_feature(class_labels),\n",
        "               'image/instance_labels':_int64_feature(instance_labels)}\n",
        "\n",
        "    # example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "    # return example_proto.SerializeToString()\n",
        "    return tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "\n",
        "# ----------------------------------------------------------------------------\n",
        "\n",
        "def main(dataset_path, output_path):\n",
        "    samples = []\n",
        "    print(\"Reading data list...\")\n",
        "    for id_name in tqdm(os.listdir(dataset_path)):\n",
        "        img_paths = glob(os.path.join(dataset_path, id_name, '*.dcm'))\n",
        "        for img_path in img_paths:\n",
        "            filename = os.path.join(id_name, os.path.basename(img_path))\n",
        "            samples.append((img_path, id_name, filename))\n",
        "    random.shuffle(samples)\n",
        "\n",
        "    print(\"Writing tfrecord file...\")\n",
        "    with tf.io.TFRecordWriter(output_path) as writer:\n",
        "        for img_path, id_name, filename in tqdm(samples):\n",
        "            tf_example = make_example(img_str=open(img_path, 'rb').read(),\n",
        "                                      source_id=int(id_name),\n",
        "                                      filename=str.encode(filename))\n",
        "            writer.write(tf_example.SerializeToString())\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main(dataset_path, \"kface_bin.tfrecord\")"
      ],
      "metadata": {
        "id": "SKrAQ-2iY28_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tqdm import tqdm\n",
        "from glob import glob\n",
        "import random\n",
        "import tensorflow as tf\n",
        "\n",
        "dataset_path= '/content/drive/MyDrive/cakd_colab/python_practice/smc/1.3.6.1.4.1.14519.5.2.1.6279.6001.105756658031515062000744821260'\n",
        "\n",
        "def _bytes_feature(value):\n",
        "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
        "    if isinstance(value, type(tf.constant(0))):\n",
        "        value = value.numpy()\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "\n",
        "def _float_feature(value):\n",
        "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
        "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
        "\n",
        "\n",
        "def _int64_feature(value):\n",
        "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
        "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "\n",
        "def make_example(img_str, source_id, filename):\n",
        "    # Create a dictionary with features that may be relevant.\n",
        "    feature = {'image/source_id': _int64_feature(source_id),\n",
        "               'image/filename': _bytes_feature(filename),\n",
        "               'image/encoded': _bytes_feature(img_str),\n",
        "               # -----------------------------------------\n",
        "               'image/height': _int64_feature(shape[0]),\n",
        "               'image/width': _int64_feature(shape[1]),\n",
        "               'image/channels': _int64_feature(shape[2]),\n",
        "               'image/shape': _int64_feature(shape),\n",
        "               'image/image_data':_bytes_feature(image_data.tostring()),\n",
        "               'image/superpixels':_bytes_feature(superpixels.tostring()),\n",
        "               'image/mask_instance':_bytes_feature(mask_instance.tostring()),\n",
        "               'image/mask_class':_bytes_feature(mask_class.tostring()),\n",
        "               'image/class_labels':_int64_feature(class_labels),\n",
        "               'image/instance_labels':_int64_feature(instance_labels)}\n",
        "\n",
        "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "    return example_proto.SerializeToString()\n",
        "    # return tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------------------------\n",
        "\n",
        "def main(dataset_path, output_path):\n",
        "    samples = []\n",
        "    print(\"Reading data list...\")\n",
        "    for id_name in tqdm(os.listdir(dataset_path)):\n",
        "        img_paths = glob(os.path.join(dataset_path, id_name, '*.dcm'))\n",
        "        for img_path in img_paths:\n",
        "            filename = os.path.join(id_name, os.path.basename(img_path))\n",
        "            samples.append((img_path, id_name, filename))\n",
        "    random.shuffle(samples)\n",
        "\n",
        "    print(\"Writing tfrecord file...\")\n",
        "    with tf.io.TFRecordWriter(output_path) as writer:\n",
        "        for img_path, id_name, filename in tqdm(samples):\n",
        "            tf_example = make_example(img_str=open(img_path, 'rb').read(),\n",
        "                                      source_id=int(id_name),\n",
        "                                      filename=str.encode(filename))\n",
        "            writer.write(tf_example.SerializeToString())\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main(dataset_path, \"kface_bin.tfrecord\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXF-rf8K3xTO",
        "outputId": "3aec1ea2-8485-45e6-c9ca-06a5c765ac4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading data list...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 121/121 [00:00<00:00, 6132.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing tfrecord file...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tf_record = \"/content/kface_bin.tfrecord\"\n",
        "filename = \"/content/kface_bin.tfrecord\"\n",
        "filenames= [filename]\n",
        "raw_dataset = tf.data.TFRecordDataset(filenames)\n",
        "raw_dataset\n",
        "\n",
        "# example_proto = tf.train.Example.FromString(tf_record)\n",
        "# example_proto"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sJk4qJV1ZHz",
        "outputId": "5ec4d7f8-ebfe-478b-92a9-47e05fa4406b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TFRecordDatasetV2 element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for raw_record in raw_dataset.take(10):\n",
        "  print(repr(raw_record))"
      ],
      "metadata": {
        "id": "J2mkMCaGXgqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a description of the features.\n",
        "feature_description = {\n",
        "    'feature0': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
        "    'feature1': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
        "    'feature2': tf.io.FixedLenFeature([], tf.string, default_value=''),\n",
        "    'feature3': tf.io.FixedLenFeature([], tf.float32, default_value=0.0),\n",
        "}\n",
        "\n",
        "def _parse_function(example_proto):\n",
        "  # Parse the input `tf.train.Example` proto using the dictionary above.\n",
        "  return tf.io.parse_single_example(example_proto, feature_description)"
      ],
      "metadata": {
        "id": "A6BgFIWqXnEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parsed_dataset = raw_dataset.map(_parse_function)\n",
        "parsed_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eb3yfzO4XpCp",
        "outputId": "5277e8be-29fd-4e5a-e70f-47c921f7cf38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<MapDataset element_spec={'feature0': TensorSpec(shape=(), dtype=tf.int64, name=None), 'feature1': TensorSpec(shape=(), dtype=tf.int64, name=None), 'feature2': TensorSpec(shape=(), dtype=tf.string, name=None), 'feature3': TensorSpec(shape=(), dtype=tf.float32, name=None)}>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for parsed_record in parsed_dataset.take(10):\n",
        "  print(repr(parsed_record))"
      ],
      "metadata": {
        "id": "NKX5GElJXtiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for raw_record in raw_dataset.take(1):\n",
        "  example = tf.train.Example()\n",
        "  example.ParseFromString(raw_record.numpy())\n",
        "  print(example)"
      ],
      "metadata": {
        "id": "8m7pPl-62pd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rfoWrpQ32t6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lsAa958L2t4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8e-_f0e82t2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def _parse_tfrecord():\n",
        "    def parse_tfrecord(tfrecord):\n",
        "        features = {'image/source_id': tf.io.FixedLenFeature([], tf.int64),\n",
        "                    'image/filename': tf.io.FixedLenFeature([], tf.string),\n",
        "                    'image/encoded': tf.io.FixedLenFeature([], tf.string),\n",
        "                    # ---------------------------------------------------\n",
        "                    'image/height': _int64_feature(shape[0]),\n",
        "                    'image/width': _int64_feature(shape[1]),\n",
        "                    'image/channels': _int64_feature(shape[2]),\n",
        "                    'image/shape': _int64_feature(shape),\n",
        "                    'image/image_data':_bytes_feature(image_data.tostring()),\n",
        "                    'image/superpixels':_bytes_feature(superpixels.tostring()),\n",
        "                    'image/mask_instance':_bytes_feature(mask_instance.tostring()),\n",
        "                    'image/mask_class':_bytes_feature(mask_class.tostring()),\n",
        "                    'image/class_labels':_int64_feature(class_labels),\n",
        "                    'image/instance_labels':_int64_feature(instance_labels)}\n",
        "\n",
        "\n",
        "        x = tf.io.parse_single_example(tfrecord, features)\n",
        "        x_train = tf.image.decode_jpeg(x['image/encoded'], channels=3)\n",
        "\n",
        "        y_train = tf.cast(x['image/source_id'], tf.float32)\n",
        "        x_train = _transform_images()(x_train)\n",
        "        y_train = _transform_targets(y_train)\n",
        "        return (x_train, y_train), y_train\n",
        "    return parse_tfrecord\n",
        "\n",
        "\n",
        "def _transform_images():\n",
        "    def transform_images(x_train):\n",
        "        x_train = tf.image.resize(x_train, (128, 128))\n",
        "        x_train = tf.image.random_crop(x_train, (112, 112, 3))\n",
        "        x_train = tf.image.random_flip_left_right(x_train)\n",
        "        x_train = tf.image.random_saturation(x_train, 0.6, 1.4)\n",
        "        x_train = tf.image.random_brightness(x_train, 0.4)\n",
        "        x_train = x_train / 255\n",
        "        return x_train\n",
        "    return transform_images\n",
        "\n",
        "\n",
        "def _transform_targets(y_train):\n",
        "    return y_train"
      ],
      "metadata": {
        "id": "Yko3NuSK41bf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_tfrecord_dataset(tfrecord_name, batch_size, shuffle=True, buffer_size=10240):\n",
        "    \"\"\"load dataset from tfrecord\"\"\"\n",
        "    raw_dataset = tf.data.TFRecordDataset(tfrecord_name)\n",
        "    raw_dataset = raw_dataset.repeat()\n",
        "    if shuffle:\n",
        "        raw_dataset = raw_dataset.shuffle(buffer_size=buffer_size)\n",
        "    dataset = raw_dataset.map(\n",
        "        _parse_tfrecord(),\n",
        "        num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
        "    )\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "wXt9MPMK41Y4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time \n",
        "\n",
        "tfr= '/content/kface_bin.tfrecord'\n",
        "tf_record= load_tfrecord_dataset(tfr, batch_size=128)\n",
        "tf_record= iter(tf_record)\n",
        "\n",
        "# start= time.time()\n",
        "# for _ in tqdm(range(121)):\n",
        "#   inputs, labels = next(tf_record)\n",
        "\n",
        "# print(time.time()-start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "9Po_Knp36Cu1",
        "outputId": "cdf2f057-78f2-4de4-939e-88d0b942e53f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-7a9ab26b5158>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtfr\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'/content/kface_bin.tfrecord'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtf_record\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mload_tfrecord_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtf_record\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_record\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-c097b198a497>\u001b[0m in \u001b[0;36mload_tfrecord_dataset\u001b[0;34m(tfrecord_name, batch_size, shuffle, buffer_size)\u001b[0m\n\u001b[1;32m      7\u001b[0m     dataset = raw_dataset.map(\n\u001b[1;32m      8\u001b[0m         \u001b[0m_parse_tfrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     )\n\u001b[1;32m     11\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2022\u001b[0m           \u001b[0mdeterministic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2023\u001b[0m           \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2024\u001b[0;31m           name=name)\n\u001b[0m\u001b[1;32m   2025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2026\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mflat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m   5236\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5237\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5238\u001b[0;31m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[1;32m   5239\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdeterministic\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5240\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deterministic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"default\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/structured_function.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mfn_factory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace_tf_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefun_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m     \u001b[0;31m# There is no graph to add in eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0madd_to_graph\u001b[0m \u001b[0;34m&=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3069\u001b[0m     \"\"\"\n\u001b[1;32m   3070\u001b[0m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0;32m-> 3071\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   3072\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3073\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3034\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3035\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3036\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3037\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3038\u001b[0m       captured = object_identity.ObjectIdentitySet(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_call_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3292\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3293\u001b[0m           self._function_cache.add(cache_key, cache_key_deletion_observer,\n\u001b[1;32m   3294\u001b[0m                                    graph_function)\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3138\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3139\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3140\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3141\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3142\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1159\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/structured_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    246\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m    247\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/structured_function.py\u001b[0m in \u001b[0;36mwrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    175\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_should_unpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0m_should_pack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    690\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: in user code:\n\n    File \"<ipython-input-6-0ac7a8e1f6ce>\", line 4, in parse_tfrecord  *\n        features = {'image/source_id': tf.io.FixedLenFeature([], tf.int64),\n\n    NameError: name 'shape' is not defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "/content/kface_bin.tfrecord"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "VuICXLqO5apP",
        "outputId": "5ed84103-38b2-41c8-e8af-3f690152e2ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-17-abeb5609ffe1>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    content(/kface_bin.tfrecord)\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ea-nc-XZ41WE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AKd7DK-b41Sn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9KCT9jbu41QB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "C2f2cNQI41NW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8Ds1sEKe3xQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "F-BXYoTT3w5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jUZK3llv3w2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "b0eCupx83wz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# imagepath= '/content/drive/MyDrive/cakd_colab/python_practice/smc/1.3.6.1.4.1.14519.5.2.1.6279.6001.105756658031515062000744821260'\n",
        "# if not os.path.exists(imagepath):\n",
        "#   print(imagepath + 'not exist')\n",
        "#   return\n",
        "  \n",
        "# imgpaths= glob(os.path.join(imagepath,\"*.dcm\"))\n",
        "# for imgPath in imgpaths:\n",
        "#   image_bytes= dcm.dcmread(imgPath)\n",
        "#   image= image_bytes.pixel_array\n",
        "#   images.append(image)\n"
      ],
      "metadata": {
        "id": "jgMsTpVe3xVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TEST for each code ★★★★★★★"
      ],
      "metadata": {
        "id": "R4DhPjY0ae-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pydicom as dcm\n",
        "import pathlib\n",
        "import os\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def encode2TfRecord():\n",
        "    flag= 1\n",
        "    imagepath= '/content/drive/MyDrive/cakd_colab/python_practice/smc/1.3.6.1.4.1.14519.5.2.1.6279.6001.105756658031515062000744821260'\n",
        "    if not os.path.exists(imagepath):\n",
        "        print(imagepath + 'not exist')\n",
        "        return\n",
        "    allFulldose= glob(os.path.join(imagepath,\"*.dcm\"))\n",
        "\n",
        "    def path2img(imgpaths):\n",
        "        images= []\n",
        "        for imgPath in imgpaths:\n",
        "            image_bytes= dcm.dcmread(imgPath)\n",
        "\n",
        "            image= image_bytes.pixel_array\n",
        "            images.append(image)\n",
        "        return images\n",
        "\n",
        "    # print(len(allFulldose))\n",
        "    # fulldose_imgs = path2img(allFulldose)\n",
        "    # fulldose_imgs = np.array(fulldose_imgs,dtype='int16')\n",
        "    # dataset = tf.data.Dataset.from_tensor_slices((fulldose_imgs))\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "    # for elem in dataset:\n",
        "    #   print(elem.numpy())\n",
        "\n",
        "    def _float_feature(value):\n",
        "        \"\"\"Returns a float_list from a float / double.\"\"\"\n",
        "        return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
        "\n",
        "\n",
        "    def _int64_feature(value):\n",
        "        \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
        "        return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "    def _bytes_feature(value):\n",
        "        '''Returns a bytes_list from a string / byte.'''\n",
        "        if  isinstance(value, type(tf.constant(0))):\n",
        "            value= value.numpy() # ByteList won't unpack a string from an EagerTensor\n",
        "        return tf.train.Feature(bytes_list= tf.train.BytesList(value=[value]))\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "    def serialize_exemple(full_img):\n",
        "        '''Creates a tf.Example message ready to be written to a file'''\n",
        "        # Creates a dictionary message readyto be written to a file\n",
        "        # data typecencode2TfRecord\n",
        "    \n",
        "        full_img= full_img.numpy().tobytes()\n",
        "        # full_img= full_img.tobytes()\n",
        "\n",
        "        feature= {\n",
        "            'full_img': _bytes_feature(full_img),\n",
        "            # --------------------------------------------------\n",
        "            'image/source_id': tf.io.FixedLenFeature([full_img], tf.int64),\n",
        "            'image/filename': tf.io.FixedLenFeature([full_img], tf.string),\n",
        "            'image/encoded': tf.io.FixedLenFeature([full_img], tf.string),\n",
        "            # ---------------------------------------------------\n",
        "            'image/height': _int64_feature(full_img.shape[0]),\n",
        "            'image/width': _int64_feature(full_img.shape[1]),\n",
        "            'image/channels': _int64_feature(full_img.shape[2]),\n",
        "            'image/shape': _int64_feature(full_img.shape),\n",
        "            'image/image_data':_bytes_feature(full_img.image_data.tostring()),\n",
        "            'image/superpixels':_bytes_feature(full_img.superpixels.tostring()),\n",
        "            'image/mask_instance':_bytes_feature(full_img.mask_instance.tostring()),\n",
        "            'image/mask_class':_bytes_feature(full_img.mask_class.tostring()),\n",
        "            'image/class_labels':_int64_feature(full_img.class_labels),\n",
        "            'image/instance_labels':_int64_feature(full_img.instance_labels)\n",
        "        }\n",
        "\n",
        "        # Create a Features message using tf.train.Example.\n",
        "        example_proto= tf.train.Example(features= tf.train.Features(feature= feature))\n",
        "        return example_proto.SerializeToString()\n",
        "\n",
        "    img= path2img(allFulldose)[0]\n",
        "    print(serialize_exemple(img))\n",
        "    # for img in fulldose_imgs:\n",
        "    #   print(serialize_exemple(img))\n",
        "\n",
        "encode2TfRecord()"
      ],
      "metadata": {
        "id": "ihZl30DMuqtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pydicom as dcm\n",
        "import pathlib\n",
        "import os\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def encode2TfRecord():\n",
        "    flag= 1\n",
        "    imagepath= '/content/drive/MyDrive/cakd_colab/python_practice/smc/1.3.6.1.4.1.14519.5.2.1.6279.6001.105756658031515062000744821260'\n",
        "    if not os.path.exists(imagepath):\n",
        "        print(imagepath + 'not exist')\n",
        "        return\n",
        "    allFulldose= glob(os.path.join(imagepath,\"*.dcm\"))\n",
        "\n",
        "    def path2img(imgpaths):\n",
        "        images= []\n",
        "        for imgPath in imgpaths:\n",
        "            image_bytes= dcm.dcmread(imgPath)\n",
        "\n",
        "            image= image_bytes.pixel_array\n",
        "            images.append(image)\n",
        "        return images\n",
        "\n",
        "    print(len(allFulldose))\n",
        "    fulldose_imgs = path2img(allFulldose)\n",
        "    fulldose_imgs = np.array(fulldose_imgs,dtype='int16')\n",
        "    # dataset = tf.data.Dataset.from_tensor_slices((fulldose_imgs))\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "    # for elem in dataset:\n",
        "    #   print(elem.numpy())\n",
        "\n",
        "    def _float_feature(value):\n",
        "        \"\"\"Returns a float_list from a float / double.\"\"\"\n",
        "        return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
        "\n",
        "\n",
        "    def _int64_feature(value):\n",
        "        \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
        "        return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "    def _bytes_feature(value):\n",
        "        '''Returns a bytes_list from a string / byte.'''\n",
        "        if  isinstance(value, type(tf.constant(0))):\n",
        "            value= value.numpy() # ByteList won't unpack a string from an EagerTensor\n",
        "        return tf.train.Feature(bytes_list= tf.train.BytesList(value=[value]))\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "    def serialize_example(full_img):\n",
        "        '''Creates a tf.Example message ready to be written to a file'''\n",
        "        # Creates a dictionary message readyto be written to a file\n",
        "        # data typecencode2TfRecord\n",
        "    \n",
        "        # full_img_bytes= full_img.numpy().tobytes()\n",
        "        full_img_bytes= full_img.tobytes()\n",
        "\n",
        "        feature= {\n",
        "            'full_img': _bytes_feature(full_img_bytes), \n",
        "            # feature 여러개 넣으면  TypeError: MergeFrom() takes exactly one argument (3 given) 이 에러남 ㅠ\n",
        "            # # --------------------------------------------------\n",
        "            # 'image/source_id': tf.io.FixedLenFeature([full_img], tf.int64),\n",
        "            # 'image/filename': tf.io.FixedLenFeature([full_img], tf.string),\n",
        "            # 'image/encoded': tf.io.FixedLenFeature([full_img], tf.string),\n",
        "            # # ---------------------------------------------------\n",
        "            # 'image/height': _int64_feature(full_img.shape[0]),\n",
        "            # 'image/width': _int64_feature(full_img.shape[1]),\n",
        "            # 'image/channels': _int64_feature(full_img.shape[2]),\n",
        "            # 'image/shape': _int64_feature(full_img.shape),\n",
        "            # 'image/image_data':_bytes_feature(full_img.image_data.tostring()),\n",
        "            # 'image/superpixels':_bytes_feature(full_img.superpixels.tostring()),\n",
        "            # 'image/mask_instance':_bytes_feature(full_img.mask_instance.tostring()),\n",
        "            # 'image/mask_class':_bytes_feature(full_img.mask_class.tostring()),\n",
        "            # 'image/class_labels':_int64_feature(full_img.class_labels),\n",
        "            # 'image/instance_labels':_int64_feature(full_img.instance_labels)\n",
        "        }\n",
        "\n",
        "        # Create a Features message using tf.train.Example.\n",
        "        example_proto= tf.train.Example(features= tf.train.Features(feature= feature))\n",
        "        return example_proto.SerializeToString()\n",
        "\n",
        "    # img= path2img(allFulldose)[0]\n",
        "    # print(serialize_example(img))\n",
        "\n",
        "    for img in fulldose_imgs:\n",
        "      # print(serialize_example(img))\n",
        "      serialized_example= serialize_example(img)\n",
        "      example_proto= tf.train.Example.FromString(serialized_example)\n",
        "      print(example_proto)\n",
        "\n",
        "    filename = 'test.tfrecord'\n",
        "    output_path=''\n",
        "\n",
        "    # with tf.io.TFRecordWriter(output_path) as writer:\n",
        "    with tf.io.TFRecordWriter(filename) as writer:\n",
        "      for img in tqdm(dataset):\n",
        "        tf_example= serialize_example(img)\n",
        "      # writer.writer(tf_example.SerializeToString())\n",
        "      writer.writer(tf_example)\n",
        "\n",
        "encode2TfRecord()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 583
        },
        "id": "4IfymjEQaSkM",
        "outputId": "d3842ed7-94b9-47a9-81a5-d54fe7848c28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n",
            "  0%|          | 0/121 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-c9cdbfe99d7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_example\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m \u001b[0mencode2TfRecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-32-c9cdbfe99d7e>\u001b[0m in \u001b[0;36mencode2TfRecord\u001b[0;34m()\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFRecordWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mtf_example\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mserialize_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;31m# writer.writer(tf_example.SerializeToString())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_example\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-c9cdbfe99d7e>\u001b[0m in \u001b[0;36mserialize_example\u001b[0;34m(full_img)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# full_img_bytes= full_img.numpy().tobytes()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mfull_img_bytes\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mfull_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         feature= {\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnp_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m         np_config.enable_numpy_behavior()\"\"\".format(type(self).__name__, name))\n\u001b[0;32m--> 513\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'tobytes'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bRXtu08j0bxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "http://solarisailab.com/archives/2603"
      ],
      "metadata": {
        "id": "n6gNRTcAtcg7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZK97Bz0JtcW2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# record_iterator = tf.compat.v1.io.tf_record_iterator(path='/content/kface_bin.tfrecord')\n",
        "\n",
        "# for string_record in record_iterator:\n",
        "#   example = tf.train.Example()\n",
        "#   example.ParseFromString(string_record)\n",
        "\n",
        "#   print(example)\n",
        "  "
      ],
      "metadata": {
        "id": "gPzsf0AJsODE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  오키..다시시도"
      ],
      "metadata": {
        "id": "n4MQbJjL2ntW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 함수 모음\n",
        "def _bytes_feature(value):\n",
        "    if isinstance(value, type(tf.constant(0))):\n",
        "        value = value.numpy()\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "\n",
        "# def serialize_example(image, mask):\n",
        "#     \"\"\"Serialize image and mask data to create tfrecord\"\"\"\n",
        "#     if image.ndim == 2:\n",
        "#         image = tf.expand_dims(image, -1)\n",
        "\n",
        "#     image = tf.image.encode_png(image)\n",
        "#     mask = tf.expand_dims(mask, -1)\n",
        "#     mask = tf.image.encode_png(mask)\n",
        "#     feature = {\n",
        "#         \"image\": _bytes_feature(image),\n",
        "#         \"mask\": _bytes_feature(mask),\n",
        "#     }\n",
        "\n",
        "#     example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "#     return example_proto.SerializeToString()\n",
        "\n",
        "# def serialize_example(image):\n",
        "#     \"\"\"Serialize image and mask data to create tfrecord\"\"\"\n",
        "#     if image.ndim == 2:\n",
        "#         image = tf.expand_dims(image, -1)\n",
        "\n",
        "#     image = tf.image.encode_png(image)\n",
        "#     # mask = tf.expand_dims(mask, -1)\n",
        "#     # mask = tf.image.encode_png(mask)\n",
        "#     feature = {\n",
        "#         \"image\": _bytes_feature(image),\n",
        "#         # \"mask\": _bytes_feature(mask),\n",
        "#     }\n",
        "\n",
        "#     example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "#     return example_proto.SerializeToString()\n",
        "\n",
        "\n",
        "def serialize_example(image):\n",
        "    \"\"\"Serialize image and mask data to create tfrecord\"\"\"\n",
        "    if image.ndim == 2:\n",
        "        image = tf.expand_dims(image, -1)\n",
        "\n",
        "    # image = tf.image.encode_png(image)\n",
        "    image= image.numpy().tobytes()\n",
        "\n",
        "    feature = {\n",
        "        \"image\": _bytes_feature(image),\n",
        "        # \"mask\": _bytes_feature(mask),\n",
        "    }\n",
        "\n",
        "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "    return example_proto.SerializeToString()\n",
        "\n",
        "\n",
        "\n",
        "def decode_example(example):\n",
        "    \"\"\"Decode a serialized example.\"\"\"\n",
        "    example = tf.io.parse_single_example(\n",
        "        example,\n",
        "        {\n",
        "            \"image\": tf.io.FixedLenFeature([], tf.string),\n",
        "            # \"mask\": tf.io.FixedLenFeature([], tf.string),\n",
        "        },\n",
        "    )\n",
        "    image = tf.image.decode_png(example[\"image\"])\n",
        "    image = tf.image.grayscale_to_rgb(image)\n",
        "    # mask = tf.image.decode_png(example[\"mask\"])\n",
        "    # return tf.cast(image, tf.float32), tf.cast(mask, tf.float32) / 255.0\n",
        "    return tf.cast(image, tf.float32)\n",
        "\n",
        "\n",
        "def mask2rle(img, width, height):\n",
        "    rle = []\n",
        "    lastColor = 0\n",
        "    currentPixel = 0\n",
        "    runStart = -1\n",
        "    runLength = 0\n",
        "\n",
        "    for x in range(width):\n",
        "        for y in range(height):\n",
        "            currentColor = img[x][y]\n",
        "            if currentColor != lastColor:\n",
        "                if currentColor == 255:\n",
        "                    runStart = currentPixel\n",
        "                    runLength = 1\n",
        "                else:\n",
        "                    rle.append(str(runStart))\n",
        "                    rle.append(str(runLength))\n",
        "                    runStart = -1\n",
        "                    runLength = 0\n",
        "                    currentPixel = 0\n",
        "            elif runStart > -1:\n",
        "                runLength += 1\n",
        "            lastColor = currentColor\n",
        "            currentPixel += 1\n",
        "\n",
        "    return \" \".join(rle)\n",
        "\n",
        "\n",
        "def rle2mask(rle, width, height):\n",
        "    mask = np.zeros(width * height)\n",
        "    array = np.asarray([int(x) for x in rle.split()])\n",
        "    starts = array[0::2]\n",
        "    lengths = array[1::2]\n",
        "\n",
        "    current_position = 0\n",
        "    for index, start in enumerate(starts):\n",
        "        current_position += start\n",
        "        mask[current_position : current_position + lengths[index]] = 255\n",
        "        current_position += lengths[index]\n",
        "\n",
        "    return mask.reshape(width, height)"
      ],
      "metadata": {
        "id": "vOpFM1DI26L9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import \n",
        "import tensorflow as tf\n",
        "from pydicom import dcmread\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import pydicom"
      ],
      "metadata": {
        "id": "8Rwppb8SsOAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1개 테스트 (check error)\n",
        "data_path= '/content/drive/MyDrive/cakd_colab/python_practice/smc/1.3.6.1.4.1.14519.5.2.1.6279.6001.105756658031515062000744821260'\n",
        "out_path= '/content/drive/MyDrive/cakd_colab/python_practice/smc/'\n",
        "\n",
        "data_path= Path(data_path)\n",
        "dicom_paths= glob(os.path.join(data_path,'*.dcm'))\n",
        "\n",
        "\n",
        "for idx, filepath in enumerate(dicom_paths):\n",
        "  ds= pydicom.dcmread(filepath)\n",
        "  img_raw= ds.pixel_array\n",
        "\n",
        "  mask = np.full_like(img_raw, True)\n",
        "  mask[img_raw == -2000] = False\n",
        "  img_raw[img_raw == -2000] =0\n",
        "\n",
        "  max_val= np.max(img_raw)\n",
        "\n",
        "  img_raw= (img_raw / max_val).astype(np.float32)\n",
        "  \n",
        "\n",
        "\n",
        "  # dcm= dcmread(dicom_path)\n",
        "  # print(type(dcm))\n",
        "  # image= dcm.pixel_array\n",
        "  \n",
        "  # print(image)\n",
        "  # if image.ndim == 2:\n",
        "  #     image = tf.expand_dims(image, -1)\n",
        "  \n",
        "  # 이미지 Unknown image file format. One of JPEG, PNG, GIF, BMP required. 인데\n",
        "  # 얘네 하면 오류남 ㅠ 얘네 지우고 tobytes 하면 오류안났다가 decode할 때 오류남\n",
        "\n",
        "  # print(type(image))\n",
        "  # print(image.dtype)\n",
        "\n",
        "  # image= image.astype(np.uint8)\n",
        "  # image= image.numpy()\n",
        "#   # image= tf.one_hot(tf.cast(tf.reshape(image, -1), dtype=tf.int32), depth=3)\n",
        "  # image = tf.image.encode_png(image)\n",
        "\n",
        "  # image = tf.io.encode_png(image)\n",
        "\n",
        "\n",
        "#   image= image.numpy().tobytes()\n",
        "#   feature = {\n",
        "#           \"image\": _bytes_feature(image),\n",
        "#           # \"mask\": _bytes_feature(mask),\n",
        "#       }\n",
        "#   example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "#   example_proto= example_proto.SerializeToString()\n",
        "#   print(example_proto)\n",
        "  break\n",
        "\n",
        "\n",
        "\n",
        "# # decode_example(example_proto)"
      ],
      "metadata": {
        "id": "W9HkidFlIayx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path= '/content/drive/MyDrive/cakd_colab/python_practice/smc/1.3.6.1.4.1.14519.5.2.1.6279.6001.105756658031515062000744821260'\n",
        "out_path= '/content/drive/MyDrive/cakd_colab/python_practice/smc/'\n",
        "\n",
        "def siim_to_tfrecords(siim_data_path, tfrecord_path, include_nofindings=False):\n",
        "  data_path= Path(siim_data_path)\n",
        "  dicom_paths= glob(os.path.join(data_path,'*.dcm'))\n",
        "\n",
        "  with tf.io.TFRecordWriter(str(tfrecord_path)) as writer:\n",
        "    for dicom_path in tqdm(dicom_paths):\n",
        "      # index= dicom_path.stem # 확장자를 제외한 파일명 부분 추출\n",
        "\n",
        "      # read image \n",
        "      dcm= dcmread(dicom_path)\n",
        "      image= dcm.pixel_array\n",
        "\n",
        "      # append them to the tfrecord file\n",
        "      writer.write(serialize_example(image))\n",
        "\n",
        "# siim_to_tfrecords(data_path,out_path+'test.tfrecord')\n",
        "\n",
        "def load_siim(data_path,out_path, include_nofindings=False):\n",
        "  data_path= Path(data_path)\n",
        "  tfrecord= '/content/drive/MyDrive/cakd_colab/python_practice/smc/' + 'test.tfrecord'\n",
        "\n",
        "  # if include_nofindings:\n",
        "  #   tfrecord_path += \"_all.tfrecords\"\n",
        "  # else:\n",
        "  #   tfrecord_path += '_findings_only.tfrecords'\n",
        "  \n",
        "  # if not tfrecord_path.exists():\n",
        "  #   siim_to_tfrecords(data_path,out_path+'test.tfrecord')\n",
        "\n",
        "  dataset= tf.data.TFRecordDataset(str(tfrecord))\n",
        "\n",
        "  return dataset.map(decode_example)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "l-YuP6Y5sN-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "siim_to_tfrecords(data_path,out_path+'test.tfrecord')"
      ],
      "metadata": {
        "id": "YeCCuyCGsN8A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed2083a3-9b0f-4cae-87ac-caeba1b99e39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 121/121 [00:01<00:00, 108.19it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset= load_siim(data_path,out_path)\n"
      ],
      "metadata": {
        "id": "Mtm_-ZPIsN5T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3b58f2c-640f-43d4-dabf-02c0ab61171b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<MapDataset element_spec=TensorSpec(shape=(None, None, 3), dtype=tf.float32, name=None)>"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-kSG6AFaNlyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qoQqR4HUNlv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wLtfSR3ONlrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OghHw9TgNlpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MWigUvTuNlmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lQVqCfLOa7DJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IqOzH128kt8h"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pydicom as dcm\n",
        "import pathlib\n",
        "import os\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def encode2TfRecord():\n",
        "    flag= 1\n",
        "    imagepath= '/content/drive/MyDrive/cakd_colab/python_practice/smc/1.3.6.1.4.1.14519.5.2.1.6279.6001.105756658031515062000744821260'\n",
        "    if not os.path.exists(imagepath):\n",
        "        print(imagepath + 'not exist')\n",
        "        return\n",
        "    allFulldose= glob(os.path.join(imagepath,\"*.dcm\"))\n",
        "\n",
        "    def path2img(imgpaths):\n",
        "        images= []\n",
        "        for imgPath in imgpaths:\n",
        "            image_bytes= dcm.dcmread(imgPath)\n",
        "\n",
        "            image= image_bytes.pixel_array\n",
        "            images.append(image)\n",
        "        return images\n",
        "\n",
        "    print(len(allFulldose))\n",
        "    fulldose_imgs = path2img(allFulldose)\n",
        "    fulldose_imgs = np.array(fulldose_imgs,dtype='int16')\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((fulldose_imgs))\n",
        "\n",
        "\n",
        "    def _bytes_feature(value):\n",
        "        '''Returns a bytes_list from a string / byte.'''\n",
        "        if  isinstance(value, type(tf.constant(0))):\n",
        "            value= value.numpy() # ByteList won't unpack a string from an EagerTensor\n",
        "        return tf.train.Feature(bytes_list= tf.train.BytesList(value=[value]))\n",
        "\n",
        "    def serialize_exemple(full_img):\n",
        "        '''Creates a tf.Example message ready to be written to a file'''\n",
        "        # Creates a dictionary message readyto be written to a file\n",
        "        # data type\n",
        "\n",
        "        full_img= full_img.numpy().tobytes()\n",
        "\n",
        "        feature= {\n",
        "            'full_img': _bytes_feature(full_img)\n",
        "        }\n",
        "\n",
        "        # Create a Features message using tf.train.Example.\n",
        "        example_proto= tf.train.Example(features= tf.train.Features(feature= feature))\n",
        "        return example_proto.SerializeToString()\n",
        "        \n",
        "    def tf_serialize_example(f):\n",
        "\n",
        "        tf_string= tf.py_function(\n",
        "            serialize_exemple,\n",
        "            f, # pass these args to the above function\n",
        "            tf.string) # the return type is tf.string\n",
        "        return tf.reshape(tf_string, ())\n",
        "\n",
        "    serialized_dataset= dataset.map(tf_serialize_example)\n",
        "\n",
        "    filename= 'trainData.tfrecord'\n",
        "    writer= tf.data.experimental.TFRecordWriter(filename)\n",
        "    writer.write(serialized_dataset)\n",
        "\n",
        "    print('finished')\n",
        "    return None\n",
        "\n",
        "# ----------------------------------------------------------------------------\n",
        "\n",
        "# def decode(filename):\n",
        "#     dataset= tf.data.TFRecordDataset(filename)\n",
        "#     feature= {'full_img': tf.io.FixedLenFeature([], tf.string)}\n",
        "\n",
        "#     def _parse_example(input):\n",
        "#         feature_dic= tf.io.parse_single_example(input,feature)\n",
        "#         feature_dic['full_img']= tf.reshape(tf.io.decode_raw(feature_dic['full_img'], tf.int16),[512,512])\n",
        "#         return feature_dic['full_img']\n",
        "\n",
        "#     dataset= dataset.map(_parse_example())\n",
        "\n",
        "#     def preprocess(full):\n",
        "#         full= tf.cast(full, dtype=tf.float32)\n",
        "#         f_min= tf.reduce_min(full)\n",
        "#         f_max= tf.reduce_max(full)\n",
        "#         full= (full - f_min) / (f_max - f_min)\n",
        "#         return full\n",
        "\n",
        "#     dataset= dataset.map(preprocess)\n",
        "#     return dataset\n",
        "\n",
        "\n",
        "encode2TfRecord()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decode(filename):\n",
        "    dataset= tf.data.TFRecordDataset(filename)\n",
        "    feature= {'full_img': tf.io.FixedLenFeature([], tf.string)}\n",
        "\n",
        "    def _parse_example(input):\n",
        "        feature_dic= tf.io.parse_single_example(input,feature)\n",
        "        feature_dic['full_img']= tf.reshape(tf.io.decode_raw(feature_dic['full_img'], tf.int16),[512,512])\n",
        "        return feature_dic['full_img']\n",
        "\n",
        "    dataset= dataset.map(_parse_example())\n",
        "\n",
        "    def preprocess(full):\n",
        "        full= tf.cast(full, dtype=tf.float32)\n",
        "        f_min= tf.reduce_min(full)\n",
        "        f_max= tf.reduce_max(full)\n",
        "        full= (full - f_min) / (f_max - f_min)\n",
        "        return full\n",
        "\n",
        "    dataset= dataset.map(preprocess)\n",
        "    return dataset\n",
        "\n",
        "\n",
        "decode('/content/kface_bin.tfrecord')"
      ],
      "metadata": {
        "id": "nX7UaxBYlFAa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "f6e8448d-9db8-4c5c-9b37-f03e86ffb1ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-dd4407cae159>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/kface_bin.tfrecord'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-dd4407cae159>\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfeature_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'full_img'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_parse_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: _parse_example() missing 1 required positional argument: 'input'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/JZK00/Preprocessing-Tool/blob/0989810c07b73fede39090d2ff72a047ef869f59/MedIA_Processing/convert_dicom_to_png.py"
      ],
      "metadata": {
        "id": "vawEHFUpxM2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import division\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os \n",
        "import pydicom\n",
        "import xml.etree.ElementTree as ET\n",
        "from PIL import Image, ImageDraw\n",
        "from skimage.util import img_as_float\n",
        "from skimage.segmentation import slic\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "import scipy.ndimage\n",
        "\n",
        "# DIRECTORY_IMAGES = './'\n",
        "\n",
        "# RANDOM_SEED = 4242\n",
        "# SAMPLES_PER_FILES = 300\n",
        "\n",
        "# def get_image_data_from_pydicom(dm, q):\n",
        "#     dm = pydicom.read_file(dm)\n",
        "#     #x = 1260\n",
        "#     #y = 910\n",
        "#     #xscale = x/dm.Rows\n",
        "#     #yscale = y/dm.Columns\n",
        "#     image_data = np.array(dm.pixel_array)\n",
        "#     #image_data = np.float32(image_data)\n",
        "#     #image_data = scipy.ndimage.interpolation.zoom(image_data, [xscale,yscale])\n",
        "#     print(image_data.shape)\n",
        "\n",
        "#     for p in range(175):\n",
        "\n",
        "#         img_data = image_data[p,:,:,0]\n",
        "#         #image = img_as_float(image_data)\n",
        "#         #superpixels = slic(image_data, n_segments = 2000, compactness=0.01, max_iter=10)\n",
        "#         im = Image.fromarray(img_data)\n",
        "#         #jpeg_dir = os.makedirs(\"./datasets/jpeg_%s\"%q)\n",
        "#         ###im.save(\"./png/png_%s\"%q + \"out_%s.png\"%p)\n",
        "#         im.save(\"./png/217a\" + \"out%s.png\" % p)\n",
        "#     return image_data\n",
        "\n",
        "def _bytes_feature(value):\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def _int64_feature(value):\n",
        "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "def _convert_to_example(image_data):\n",
        "\n",
        "    \"\"\"Build an Example proto for an image example.\n",
        "    Args:\n",
        "      image_data: string, JPEG encoding of RGB image.\n",
        "      labels: list of integers, identifier for the ground truth;\n",
        "      instance: instance labels.\n",
        "      labels_text: list of strings, human-readable labels.\n",
        "      mask_instance: numpy matrix of instance.\n",
        "      mask_class: numpy matrix of class.\n",
        "      shape: 3 integers, image shapes in pixels.\n",
        "    Returns:\n",
        "      Example proto\n",
        "    \"\"\"\n",
        "    example = tf.train.Example(features=tf.train.Features(feature={\n",
        "        #'image/height': _int64_feature(shape[0]),\n",
        "        #'image/width': _int64_feature(shape[1]),\n",
        "        #'image/channels': _int64_feature(shape[2]),\n",
        "        #'image/shape': _int64_feature(shape),\n",
        "        'image/image_data':_bytes_feature(image_data.tostring()),\n",
        "        #'image/superpixels':_bytes_feature(superpixels.tostring()),\n",
        "        #'image/mask_instance':_bytes_feature(mask_instance.tostring()),\n",
        "        #'image/mask_class':_bytes_feature(mask_class.tostring()),\n",
        "        #'image/class_labels':_int64_feature(class_labels),\n",
        "        #'image/instance_labels':_int64_feature(instance_labels)\n",
        "    }))\n",
        "    return example\n",
        "\n",
        "def _add_to_tfrecord(dataset_dir, name, tfrecord_writer, q):\n",
        "    \"\"\"Loads data from image and annotations files and add them to a TFRecord.\n",
        "    Args:\n",
        "      dataset_dir: Dataset directory;\n",
        "      name: Image name to add to the TFRecord;\n",
        "      tfrecord_writer: The TFRecord writer to use for writing.\n",
        "    \"\"\"\n",
        "\n",
        "    dm = dataset_dir + DIRECTORY_IMAGES + name +'.dcm'\n",
        "    #xml = dataset_dir + DIRECTORY_ANNOTATIONS + name + '.xml'\n",
        "    image_data = get_image_data_from_pydicom(dm, q)\n",
        "    #mask_instance, mask_class, shape, class_labels, class_labels_text, instance_labels = groundtruth_to_mask(xml)\n",
        "    example = _convert_to_example(image_data)\n",
        "    tfrecord_writer.write(example.SerializeToString())\n",
        "\n",
        "def _get_output_filename(output_dir, name, idx):\n",
        "    return '%s/%s.tfrecord' % (output_dir, name)\n",
        "\n",
        "def run(dataset_dir, output_dir, name='diameter_measurement', shuffling=False):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      dataset_dir: The dataset directory where the dataset is stored.\n",
        "      output_dir: Output directory.\n",
        "    \"\"\"\n",
        "    if not tf.gfile.Exists(output_dir):\n",
        "        tf.gfile.MakeDirs(output_dir)\n",
        "    path = os.path.join(dataset_dir)\n",
        "    filenames = sorted(os.listdir(path))\n",
        "    if shuffling:\n",
        "        random.seed(RANDOM_SEED)\n",
        "        random.shuffle(filenames)\n",
        "    i = 0\n",
        "    fidx = 0\n",
        "    while i < len(filenames):\n",
        "    # Open new TFRecord file.\n",
        "        tf_filename  = _get_output_filename(output_dir, name, fidx)   \n",
        "        with tf.python_io.TFRecordWriter(tf_filename) as tfrecord_writer:\n",
        "            j = 0\n",
        "            #while i < len(filenames) and j < SAMPLES_PER_FILES:\n",
        "            for q in range(1):\n",
        "                sys.stdout.write('\\r>> Converting image %d/%d' % (i+1, len(filenames)))\n",
        "                sys.stdout.flush()\n",
        "                filename = filenames[i]\n",
        "                img_name = filename[:-4]\n",
        "                _add_to_tfrecord(dataset_dir, img_name, tfrecord_writer, q)\n",
        "                i += 1\n",
        "                j += 1\n",
        "            fidx += 1\n",
        "    print('\\nFinished converting the diameter measure dataset!')\n"
      ],
      "metadata": {
        "id": "zopj94V5deen"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}