{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "input_pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1K-1_N8ZUzoKVWC-9r-cCUAxX2EO3XTWg",
      "authorship_tag": "ABX9TyMt4ccrn8+qelkysA1TvGP1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SeunghyeChae/tmdhey/blob/main/input_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_io"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RMtX_oxbenD",
        "outputId": "550c23a4-2b29-465c-9532-0d6acce5641d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_io\n",
            "  Downloading tensorflow_io-0.24.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (23.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 23.4 MB 1.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem==0.24.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_io) (0.24.0)\n",
            "Installing collected packages: tensorflow-io\n",
            "Successfully installed tensorflow-io-0.24.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydicom"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYRPr7RFlgmV",
        "outputId": "01419080-c4f5-4c30-88cf-fc6d6313f752"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydicom\n",
            "  Downloading pydicom-2.2.2-py3-none-any.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 7.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: pydicom\n",
            "Successfully installed pydicom-2.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pydicom as dcm\n",
        "import pathlib\n",
        "import os\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "9atv7m3c3xYN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tqdm import tqdm\n",
        "from glob import glob\n",
        "import random\n",
        "import tensorflow as tf\n",
        "\n",
        "dataset_path= '/content/drive/MyDrive/cakd_colab/python_practice/smc/1.3.6.1.4.1.14519.5.2.1.6279.6001.105756658031515062000744821260'\n",
        "\n",
        "def _bytes_feature(value):\n",
        "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
        "    if isinstance(value, type(tf.constant(0))):\n",
        "        value = value.numpy()\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "\n",
        "def _float_feature(value):\n",
        "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
        "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
        "\n",
        "\n",
        "def _int64_feature(value):\n",
        "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
        "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "\n",
        "def make_example(img_str, source_id, filename):\n",
        "    # Create a dictionary with features that may be relevant.\n",
        "    feature = {'image/source_id': _int64_feature(source_id),\n",
        "               'image/filename': _bytes_feature(filename),\n",
        "               'image/encoded': _bytes_feature(img_str),\n",
        "               # -----------------------------------------\n",
        "               'image/height': _int64_feature(shape[0]),\n",
        "               'image/width': _int64_feature(shape[1]),\n",
        "               'image/channels': _int64_feature(shape[2]),\n",
        "               'image/shape': _int64_feature(shape),\n",
        "               'image/image_data':_bytes_feature(image_data.tostring()),\n",
        "               'image/superpixels':_bytes_feature(superpixels.tostring()),\n",
        "               'image/mask_instance':_bytes_feature(mask_instance.tostring()),\n",
        "               'image/mask_class':_bytes_feature(mask_class.tostring()),\n",
        "               'image/class_labels':_int64_feature(class_labels),\n",
        "               'image/instance_labels':_int64_feature(instance_labels)}\n",
        "\n",
        "    return tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "\n",
        "\n",
        "def main(dataset_path, output_path):\n",
        "    samples = []\n",
        "    print(\"Reading data list...\")\n",
        "    for id_name in tqdm(os.listdir(dataset_path)):\n",
        "        img_paths = glob(os.path.join(dataset_path, id_name, '*.dcm'))\n",
        "        for img_path in img_paths:\n",
        "            filename = os.path.join(id_name, os.path.basename(img_path))\n",
        "            samples.append((img_path, id_name, filename))\n",
        "    random.shuffle(samples)\n",
        "\n",
        "    print(\"Writing tfrecord file...\")\n",
        "    with tf.io.TFRecordWriter(output_path) as writer:\n",
        "        for img_path, id_name, filename in tqdm(samples):\n",
        "            tf_example = make_example(img_str=open(img_path, 'rb').read(),\n",
        "                                      source_id=int(id_name),\n",
        "                                      filename=str.encode(filename))\n",
        "            writer.write(tf_example.SerializeToString())\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main(dataset_path, \"kface_bin.tfrecord\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXF-rf8K3xTO",
        "outputId": "1154e008-eb9f-446d-dcc6-f1a8d5650633"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading data list...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 121/121 [00:00<00:00, 6230.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing tfrecord file...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MFMK-riZxGjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_io as tfio\n",
        "\n",
        "def _parse_tfrecord():\n",
        "    def parse_tfrecord(tfrecord):\n",
        "        features = {'image/source_id': tf.io.FixedLenFeature([], tf.int64),\n",
        "                    'image/filename': tf.io.FixedLenFeature([], tf.string),\n",
        "                    'image/encoded': tf.io.FixedLenFeature([], tf.string)}\n",
        "        x = tf.io.parse_single_example(tfrecord, features)\n",
        "        x_train = tf.image.decode_jpeg(x['image/encoded'], channels=3)\n",
        "\n",
        "        y_train = tf.cast(x['image/source_id'], tf.float32)\n",
        "        x_train = _transform_images()(x_train)\n",
        "        y_train = _transform_targets(y_train)\n",
        "        return (x_train, y_train), y_train\n",
        "    return parse_tfrecord\n",
        "\n",
        "\n",
        "def _transform_images():\n",
        "    def transform_images(x_train):\n",
        "        x_train = tf.image.resize(x_train, (128, 128))\n",
        "        x_train = tf.image.random_crop(x_train, (112, 112, 3))\n",
        "        x_train = tf.image.random_flip_left_right(x_train)\n",
        "        x_train = tf.image.random_saturation(x_train, 0.6, 1.4)\n",
        "        x_train = tf.image.random_brightness(x_train, 0.4)\n",
        "        x_train = x_train / 255\n",
        "        return x_train\n",
        "    return transform_images\n",
        "\n",
        "\n",
        "def _transform_targets(y_train):\n",
        "    return y_train"
      ],
      "metadata": {
        "id": "Yko3NuSK41bf"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_tfrecord_dataset(tfrecord_name, batch_size, shuffle=True, buffer_size=10240):\n",
        "    \"\"\"load dataset from tfrecord\"\"\"\n",
        "    raw_dataset = tf.data.TFRecordDataset(tfrecord_name)\n",
        "    raw_dataset = raw_dataset.repeat()\n",
        "    if shuffle:\n",
        "        raw_dataset = raw_dataset.shuffle(buffer_size=buffer_size)\n",
        "    dataset = raw_dataset.map(\n",
        "        _parse_tfrecord(),\n",
        "        num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
        "    )\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "wXt9MPMK41Y4"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time \n",
        "\n",
        "tfr= '/content/kface_bin.tfrecord'\n",
        "tf_record= load_tfrecord_dataset(tfr, batch_size=128)\n",
        "tf_record= iter(tf_record)\n",
        "\n",
        "start= time.time()\n",
        "for _ in tqdm(range(121)):\n",
        "  inputs, labels = next(tf_record)\n",
        "\n",
        "print(time.time()-start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "9Po_Knp36Cu1",
        "outputId": "9c4d67e5-e6cf-43a5-8151-ee775322ef21"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/121 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "StopIteration",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    835\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 836\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    837\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    821\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m           output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2922\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2923\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2924\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7185\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7186\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfRangeError\u001b[0m: End of sequence [Op:IteratorGetNext]",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-094c83c216da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m121\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_record\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    836\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 838\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mStopIteration\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "/content/kface_bin.tfrecord"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "VuICXLqO5apP",
        "outputId": "5ed84103-38b2-41c8-e8af-3f690152e2ac"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-17-abeb5609ffe1>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    content(/kface_bin.tfrecord)\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ea-nc-XZ41WE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AKd7DK-b41Sn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9KCT9jbu41QB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "C2f2cNQI41NW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8Ds1sEKe3xQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "F-BXYoTT3w5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jUZK3llv3w2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "b0eCupx83wz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# imagepath= '/content/drive/MyDrive/cakd_colab/python_practice/smc/1.3.6.1.4.1.14519.5.2.1.6279.6001.105756658031515062000744821260'\n",
        "# if not os.path.exists(imagepath):\n",
        "#   print(imagepath + 'not exist')\n",
        "#   return\n",
        "  \n",
        "# imgpaths= glob(os.path.join(imagepath,\"*.dcm\"))\n",
        "# for imgPath in imgpaths:\n",
        "#   image_bytes= dcm.dcmread(imgPath)\n",
        "#   image= image_bytes.pixel_array\n",
        "#   images.append(image)\n"
      ],
      "metadata": {
        "id": "jgMsTpVe3xVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IqOzH128kt8h"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pydicom as dcm\n",
        "import pathlib\n",
        "import os\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def encode2TfRecord():\n",
        "    flag= 1\n",
        "    imagepath= '/content/drive/MyDrive/cakd_colab/python_practice/smc/1.3.6.1.4.1.14519.5.2.1.6279.6001.105756658031515062000744821260'\n",
        "    if not os.path.exists(imagepath):\n",
        "        print(imagepath + 'not exist')\n",
        "        return\n",
        "    allFulldose= glob(os.path.join(imagepath,\"*.dcm\"))\n",
        "\n",
        "    def path2img(imgpaths):\n",
        "        images= []\n",
        "        for imgPath in imgpaths:\n",
        "            image_bytes= dcm.dcmread(imgPath)\n",
        "\n",
        "            image= image_bytes.pixel_array\n",
        "            images.append(image)\n",
        "        return images\n",
        "\n",
        "    print(len(allFulldose))\n",
        "    fulldose_imgs = path2img(allFulldose)\n",
        "    fulldose_imgs = np.array(fulldose_imgs,dtype='int16')\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((fulldose_imgs))\n",
        "\n",
        "\n",
        "    def _bytes_feature(value):\n",
        "        '''Returns a bytes_list from a string / byte.'''\n",
        "        if  isinstance(value, type(tf.constant(0))):\n",
        "            value= value.numpy() # ByteList won't unpack a string from an EagerTensor\n",
        "        return tf.train.Feature(bytes_list= tf.train.BytesList(value=[value]))\n",
        "\n",
        "    def serialize_exemple(full_img):\n",
        "        '''Creates a tf.Example message ready to be written to a file'''\n",
        "        # Creates a dictionary message readyto be written to a file\n",
        "        # data type\n",
        "\n",
        "        full_img= full_img.numpy().tobytes()\n",
        "\n",
        "        feature= {\n",
        "            'full_img': _bytes_feature(full_img)\n",
        "        }\n",
        "\n",
        "        # Create a Features message using tf.train.Example.\n",
        "        example_proto= tf.train.Example(features= tf.train.Features(feature= feature))\n",
        "        return example_proto.SerializeToString()\n",
        "        \n",
        "    def tf_serialize_example(f):\n",
        "\n",
        "        tf_string= tf.py_function(\n",
        "            serialize_exemple,\n",
        "            f, # pass these args to the above function\n",
        "            tf.string) # the return type is tf.string\n",
        "        return tf.reshape(tf_string, ())\n",
        "\n",
        "    serialized_dataset= dataset.map(tf_serialize_example)\n",
        "\n",
        "    filename= 'trainData.tfrecord'\n",
        "    writer= tf.data.experimental.TFRecordWriter(filename)\n",
        "    writer.write(serialized_dataset)\n",
        "\n",
        "    print('finished')\n",
        "    return None\n",
        "\n",
        "# ----------------------------------------------------------------------------\n",
        "\n",
        "# def decode(filename):\n",
        "#     dataset= tf.data.TFRecordDataset(filename)\n",
        "#     feature= {'full_img': tf.io.FixedLenFeature([], tf.string)}\n",
        "\n",
        "#     def _parse_example(input):\n",
        "#         feature_dic= tf.io.parse_single_example(input,feature)\n",
        "#         feature_dic['full_img']= tf.reshape(tf.io.decode_raw(feature_dic['full_img'], tf.int16),[512,512])\n",
        "#         return feature_dic['full_img']\n",
        "\n",
        "#     dataset= dataset.map(_parse_example())\n",
        "\n",
        "#     def preprocess(full):\n",
        "#         full= tf.cast(full, dtype=tf.float32)\n",
        "#         f_min= tf.reduce_min(full)\n",
        "#         f_max= tf.reduce_max(full)\n",
        "#         full= (full - f_min) / (f_max - f_min)\n",
        "#         return full\n",
        "\n",
        "#     dataset= dataset.map(preprocess)\n",
        "#     return dataset\n",
        "\n",
        "\n",
        "encode2TfRecord()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decode(filename):\n",
        "    dataset= tf.data.TFRecordDataset(filename)\n",
        "    feature= {'full_img': tf.io.FixedLenFeature([], tf.string)}\n",
        "\n",
        "    def _parse_example(input):\n",
        "        feature_dic= tf.io.parse_single_example(input,feature)\n",
        "        feature_dic['full_img']= tf.reshape(tf.io.decode_raw(feature_dic['full_img'], tf.int16),[512,512])\n",
        "        return feature_dic['full_img']\n",
        "\n",
        "    dataset= dataset.map(_parse_example())\n",
        "\n",
        "    def preprocess(full):\n",
        "        full= tf.cast(full, dtype=tf.float32)\n",
        "        f_min= tf.reduce_min(full)\n",
        "        f_max= tf.reduce_max(full)\n",
        "        full= (full - f_min) / (f_max - f_min)\n",
        "        return full\n",
        "\n",
        "    dataset= dataset.map(preprocess)\n",
        "    return dataset\n",
        "\n",
        "\n",
        "decode('/content/kface_bin.tfrecord')"
      ],
      "metadata": {
        "id": "nX7UaxBYlFAa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "f6e8448d-9db8-4c5c-9b37-f03e86ffb1ef"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-dd4407cae159>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/kface_bin.tfrecord'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-dd4407cae159>\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfeature_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'full_img'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_parse_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: _parse_example() missing 1 required positional argument: 'input'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/JZK00/Preprocessing-Tool/blob/0989810c07b73fede39090d2ff72a047ef869f59/MedIA_Processing/convert_dicom_to_png.py"
      ],
      "metadata": {
        "id": "vawEHFUpxM2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import division\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os \n",
        "import pydicom\n",
        "import xml.etree.ElementTree as ET\n",
        "from PIL import Image, ImageDraw\n",
        "from skimage.util import img_as_float\n",
        "from skimage.segmentation import slic\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "import scipy.ndimage\n",
        "\n",
        "# DIRECTORY_IMAGES = './'\n",
        "\n",
        "# RANDOM_SEED = 4242\n",
        "# SAMPLES_PER_FILES = 300\n",
        "\n",
        "# def get_image_data_from_pydicom(dm, q):\n",
        "#     dm = pydicom.read_file(dm)\n",
        "#     #x = 1260\n",
        "#     #y = 910\n",
        "#     #xscale = x/dm.Rows\n",
        "#     #yscale = y/dm.Columns\n",
        "#     image_data = np.array(dm.pixel_array)\n",
        "#     #image_data = np.float32(image_data)\n",
        "#     #image_data = scipy.ndimage.interpolation.zoom(image_data, [xscale,yscale])\n",
        "#     print(image_data.shape)\n",
        "\n",
        "#     for p in range(175):\n",
        "\n",
        "#         img_data = image_data[p,:,:,0]\n",
        "#         #image = img_as_float(image_data)\n",
        "#         #superpixels = slic(image_data, n_segments = 2000, compactness=0.01, max_iter=10)\n",
        "#         im = Image.fromarray(img_data)\n",
        "#         #jpeg_dir = os.makedirs(\"./datasets/jpeg_%s\"%q)\n",
        "#         ###im.save(\"./png/png_%s\"%q + \"out_%s.png\"%p)\n",
        "#         im.save(\"./png/217a\" + \"out%s.png\" % p)\n",
        "#     return image_data\n",
        "\n",
        "def _bytes_feature(value):\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def _int64_feature(value):\n",
        "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "def _convert_to_example(image_data):\n",
        "\n",
        "    \"\"\"Build an Example proto for an image example.\n",
        "    Args:\n",
        "      image_data: string, JPEG encoding of RGB image.\n",
        "      labels: list of integers, identifier for the ground truth;\n",
        "      instance: instance labels.\n",
        "      labels_text: list of strings, human-readable labels.\n",
        "      mask_instance: numpy matrix of instance.\n",
        "      mask_class: numpy matrix of class.\n",
        "      shape: 3 integers, image shapes in pixels.\n",
        "    Returns:\n",
        "      Example proto\n",
        "    \"\"\"\n",
        "    example = tf.train.Example(features=tf.train.Features(feature={\n",
        "        #'image/height': _int64_feature(shape[0]),\n",
        "        #'image/width': _int64_feature(shape[1]),\n",
        "        #'image/channels': _int64_feature(shape[2]),\n",
        "        #'image/shape': _int64_feature(shape),\n",
        "        'image/image_data':_bytes_feature(image_data.tostring()),\n",
        "        #'image/superpixels':_bytes_feature(superpixels.tostring()),\n",
        "        #'image/mask_instance':_bytes_feature(mask_instance.tostring()),\n",
        "        #'image/mask_class':_bytes_feature(mask_class.tostring()),\n",
        "        #'image/class_labels':_int64_feature(class_labels),\n",
        "        #'image/instance_labels':_int64_feature(instance_labels)\n",
        "    }))\n",
        "    return example\n",
        "\n",
        "def _add_to_tfrecord(dataset_dir, name, tfrecord_writer, q):\n",
        "    \"\"\"Loads data from image and annotations files and add them to a TFRecord.\n",
        "    Args:\n",
        "      dataset_dir: Dataset directory;\n",
        "      name: Image name to add to the TFRecord;\n",
        "      tfrecord_writer: The TFRecord writer to use for writing.\n",
        "    \"\"\"\n",
        "\n",
        "    dm = dataset_dir + DIRECTORY_IMAGES + name +'.dcm'\n",
        "    #xml = dataset_dir + DIRECTORY_ANNOTATIONS + name + '.xml'\n",
        "    image_data = get_image_data_from_pydicom(dm, q)\n",
        "    #mask_instance, mask_class, shape, class_labels, class_labels_text, instance_labels = groundtruth_to_mask(xml)\n",
        "    example = _convert_to_example(image_data)\n",
        "    tfrecord_writer.write(example.SerializeToString())\n",
        "\n",
        "def _get_output_filename(output_dir, name, idx):\n",
        "    return '%s/%s.tfrecord' % (output_dir, name)\n",
        "\n",
        "def run(dataset_dir, output_dir, name='diameter_measurement', shuffling=False):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      dataset_dir: The dataset directory where the dataset is stored.\n",
        "      output_dir: Output directory.\n",
        "    \"\"\"\n",
        "    if not tf.gfile.Exists(output_dir):\n",
        "        tf.gfile.MakeDirs(output_dir)\n",
        "    path = os.path.join(dataset_dir)\n",
        "    filenames = sorted(os.listdir(path))\n",
        "    if shuffling:\n",
        "        random.seed(RANDOM_SEED)\n",
        "        random.shuffle(filenames)\n",
        "    i = 0\n",
        "    fidx = 0\n",
        "    while i < len(filenames):\n",
        "    # Open new TFRecord file.\n",
        "        tf_filename  = _get_output_filename(output_dir, name, fidx)   \n",
        "        with tf.python_io.TFRecordWriter(tf_filename) as tfrecord_writer:\n",
        "            j = 0\n",
        "            #while i < len(filenames) and j < SAMPLES_PER_FILES:\n",
        "            for q in range(1):\n",
        "                sys.stdout.write('\\r>> Converting image %d/%d' % (i+1, len(filenames)))\n",
        "                sys.stdout.flush()\n",
        "                filename = filenames[i]\n",
        "                img_name = filename[:-4]\n",
        "                _add_to_tfrecord(dataset_dir, img_name, tfrecord_writer, q)\n",
        "                i += 1\n",
        "                j += 1\n",
        "            fidx += 1\n",
        "    print('\\nFinished converting the diameter measure dataset!')\n"
      ],
      "metadata": {
        "id": "zopj94V5deen"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}